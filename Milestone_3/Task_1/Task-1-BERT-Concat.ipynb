{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":41374,"status":"ok","timestamp":1682955571537,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"},"user_tz":240},"id":"JML6-VPnQUqh","outputId":"82c29980-0382-40a0-b474-ad42945c8436"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting torchtext==0.6.0\n","  Downloading torchtext-0.6.0-py3-none-any.whl (64 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.2/64.2 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (2.0.0+cu118)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (4.65.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (2.27.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (1.16.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (1.22.4)\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.98-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (3.4)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (2.0.12)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (1.11.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (3.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (3.12.0)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (2.0.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (4.5.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->torchtext==0.6.0) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->torchtext==0.6.0) (16.0.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->torchtext==0.6.0) (2.1.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->torchtext==0.6.0) (1.3.0)\n","Installing collected packages: sentencepiece, torchtext\n","  Attempting uninstall: torchtext\n","    Found existing installation: torchtext 0.15.1\n","    Uninstalling torchtext-0.15.1:\n","      Successfully uninstalled torchtext-0.15.1\n","Successfully installed sentencepiece-0.1.98 torchtext-0.6.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting datasets\n","  Downloading datasets-2.12.0-py3-none-any.whl (474 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m474.6/474.6 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.27.1)\n","Collecting huggingface-hub<1.0.0,>=0.11.0\n","  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting xxhash\n","  Downloading xxhash-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.5/212.5 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0)\n","Collecting multiprocess\n","  Downloading multiprocess-0.70.14-py310-none-any.whl (134 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n","Collecting dill<0.3.7,>=0.3.0\n","  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n","Collecting responses<0.19\n","  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n","Collecting aiohttp\n","  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.4.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.22.4)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.65.0)\n","Collecting multidict<7.0,>=4.5\n","  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting aiosignal>=1.1.2\n","  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.0.12)\n","Collecting yarl<2.0,>=1.0\n","  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n","  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n","Collecting frozenlist>=1.1.1\n","  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (3.12.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (4.5.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (1.26.15)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2022.7.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n","Installing collected packages: xxhash, multidict, frozenlist, dill, async-timeout, yarl, responses, multiprocess, huggingface-hub, aiosignal, aiohttp, datasets\n","Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 datasets-2.12.0 dill-0.3.6 frozenlist-1.3.3 huggingface-hub-0.14.1 multidict-6.0.4 multiprocess-0.70.14 responses-0.18.0 xxhash-3.2.0 yarl-1.9.2\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m48.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.14.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m95.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (2023.4.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n","Installing collected packages: tokenizers, transformers\n","Successfully installed tokenizers-0.13.3 transformers-4.28.1\n"]}],"source":["! pip install torchtext==0.6.0\n","# ! pip install torchtext==0.12.0\n","! pip install datasets\n","! pip install transformers"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lKGVdP7VAlG2","executionInfo":{"status":"ok","timestamp":1682955931928,"user_tz":240,"elapsed":11900,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}},"outputId":"d4977b4b-90f7-46fd-c42f-cfbecab0b291"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EDgQMtgJQfdJ"},"outputs":[],"source":["from datasets import load_dataset\n","\n","from transformers import BertTokenizer, BertModel, BertConfig\n","\n","import torch\n","# from torchtext.legacy import data\n","from torchtext import data"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pyyXY3Y9CJyB","executionInfo":{"status":"ok","timestamp":1682956743724,"user_tz":240,"elapsed":442,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}},"outputId":"544ee087-90d6-4dfe-cc94-a7c1296b8aba"},"outputs":[{"output_type":"stream","name":"stdout","text":["Using MODEL_CONFIG BERT\n"]}],"source":["# choose configurations for the model\n","# MODEL_CONFIG=\"LSTM\"\n","MODEL_CONFIG=\"BERT\"\n","BERT_TYPE=\"google/bert_uncased_L-4_H-256_A-4\"\n","\n","print(\"Using MODEL_CONFIG\", MODEL_CONFIG)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0zHpR9aKRA5F"},"outputs":[],"source":["PROJECT_ROOT = F\"/content/gdrive/My Drive/nlp_project_task_1_BERT/\"\n","                                          "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZHwitHvFQUqk"},"outputs":[],"source":["SEED = 42"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BS_qqwWkQUqk"},"outputs":[],"source":["torch.manual_seed(SEED)\n","torch.backends.cudnn.deterministic = True"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ztb4YGEIQUql","executionInfo":{"status":"ok","timestamp":1682956743725,"user_tz":240,"elapsed":5,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}},"outputId":"547663a6-875d-4df6-e824-83e950fba3e5"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda')"]},"metadata":{},"execution_count":51}],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","device"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":104,"referenced_widgets":["d97d97289b444b14b38a9bbd05050016","04d2cf009e92411e97f822d782f605e9","f74b641a629e4c95918565a792df8152","b588ab617cf540918875599b6efae288","92f697c153524a459b03ce30f60de9eb","06e6e0ce405c4b6b85787f0663a69e65","888e8e3856ad4883ab9df5af715558c5","890dd9bd07f8423887567924b3137b16","2096639b36e24bf9badeb2d0a03548be","dbf8390f22d5469db5e55af024ade05e","cb4ed39537bb41158479a2e9a462aa9e"]},"id":"REBQaOuFQUql","executionInfo":{"status":"ok","timestamp":1682956744018,"user_tz":240,"elapsed":296,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}},"outputId":"d34058d7-2f9b-48a3-a3d1-dd475823c3ea"},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:datasets.builder:No config specified, defaulting to: faith_dial/plain_text\n","WARNING:datasets.builder:Found cached dataset faith_dial (/root/.cache/huggingface/datasets/McGill-NLP___faith_dial/plain_text/1.0.0/70568c8ab3bbc83b603bce58fa593ab27e7f0d0cde51034e1c2073ff3e14189a)\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/7 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d97d97289b444b14b38a9bbd05050016"}},"metadata":{}}],"source":["faithdial_dataset = load_dataset(\"McGill-NLP/FaithDial\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"juF-GfX5QUqm","executionInfo":{"status":"ok","timestamp":1682956744018,"user_tz":240,"elapsed":9,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}},"outputId":"ce394d7f-afff-4d06-af32-a7957d28b7b0"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["dict_keys(['test', 'test_random_split', 'test_topic_split', 'train', 'validation', 'valid_random_split', 'valid_topic_split'])"]},"metadata":{},"execution_count":53}],"source":["faithdial_dataset.keys()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IzV6pQ3O3WLj","executionInfo":{"status":"ok","timestamp":1682956744018,"user_tz":240,"elapsed":6,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}},"outputId":"829a3b0c-70ea-4a2a-c6cb-e89ea67eaca6"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'dialog_idx': 0,\n"," 'response': 'Yeah, but once the access to the internet was a rare thing. do you remember?',\n"," 'original_response': \"No I could not! I couldn't imagine living when internet access was rare and very few people had it!\",\n"," 'history': ['Can you imagine the world without internet access?'],\n"," 'knowledge': 'Internet access was once rare, but has grown rapidly.',\n"," 'BEGIN': ['Hallucination'],\n"," 'VRM': ['Disclosure', 'Ack.']}"]},"metadata":{},"execution_count":54}],"source":["faithdial_dataset[\"train\"][0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7aHU5_UXQUqm"},"outputs":[],"source":["def critic_preprocess(dataset):\n","    \"\"\"\n","    Data items transformed into (knowledge, response, is_hallucination)\n","    \"\"\"\n","    new_dataset = []\n","    for d in dataset:\n","        # original response\n","        if d[\"original_response\"] != None:\n","            new_dataset.append({\n","                \"knowledge\": d[\"knowledge\"],\n","                \"response\": d[\"original_response\"],\n","                \"hallucination\": \"yes\" if \"Hallucination\" in d[\"BEGIN\"] else \"no\",\n","                \"history\": \" \".join(d[\"history\"]),\n","                \"all\": \" \".join(d[\"history\"]) + \" <eos> \" + d[\"knowledge\"] + \" <eos> \" + d[\"original_response\"]\n","            })\n","\n","        # new responses always aren't hallucinations\n","        new_dataset.append({\"knowledge\": d[\"knowledge\"],\n","                            \"response\": d[\"response\"],\n","                            \"hallucination\": \"no\",\n","                            \"history\": \" \".join(d[\"history\"]),\n","                            \"all\": \" \".join(d[\"history\"]) + \" <eos> \" + d[\"knowledge\"] + \" <eos> \" + d[\"response\"]\n","        })\n","    return new_dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NvX3XmUGQUqn"},"outputs":[],"source":["import json\n","\n","def dump_as_json(dataset, filename):\n","    \"\"\"\n","    Takes a list of dicts and dumps it as a json file that torchtext can parse.\n","    \"\"\"\n","    with open(filename, \"w\") as file:\n","        for d in dataset:\n","            file.write(json.dumps(d))\n","            file.write(\"\\n\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lprbGYNEQUqn"},"outputs":[],"source":["if MODEL_CONFIG == \"LSTM\":\n","    KNOWLEDGE = data.Field(tokenize='spacy', tokenizer_language=\"en_core_web_sm\", include_lengths=True)\n","    RESPONSE = data.Field(tokenize='spacy', tokenizer_language=\"en_core_web_sm\", include_lengths=True)\n","    HISTORY = data.Field(tokenize='spacy', tokenizer_language=\"en_core_web_sm\", include_lengths=True)\n","    LABEL = data.LabelField(dtype=torch.float)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Fpsa29Dknhhs"},"outputs":[],"source":["if MODEL_CONFIG == \"BERT\":\n","    tokenizer = BertTokenizer.from_pretrained('google/bert_uncased_L-4_H-256_A-4', do_lower_case=True)\n","    pad_index = tokenizer.convert_tokens_to_ids(tokenizer.pad_token)\n","    unk_index = tokenizer.convert_tokens_to_ids(tokenizer.unk_token)\n","\n","    # KNOWLEDGE = data.Field(use_vocab=False,\n","    #                         tokenize=tokenizer.encode,\n","    #                         pad_token=pad_index,\n","    #                         unk_token=unk_index,\n","    #                         include_lengths = True)\n","    # RESPONSE = data.Field(use_vocab=False,\n","    #                       tokenize=tokenizer.encode,\n","    #                       pad_token=pad_index,\n","    #                       unk_token=unk_index,\n","    #                       include_lengths=True)\n","    # HISTORY = data.Field(use_vocab=False,\n","    #                      tokenize=tokenizer.encode,\n","    #                      pad_token=pad_index,\n","    #                      unk_token=unk_index,\n","    #                      include_lengths=True)\n","\n","    ALL = data.Field(use_vocab=False,\n","                         tokenize=tokenizer.encode,\n","                         pad_token=pad_index,\n","                         unk_token=unk_index,\n","                         include_lengths=True)\n","    \n","    LABEL = data.LabelField(dtype=torch.float)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h-8aVlf5QUqn"},"outputs":[],"source":["dump_as_json(critic_preprocess(faithdial_dataset[\"test\"]), PROJECT_ROOT + \"data/faithdial_dataset_test.json\")\n","dump_as_json(critic_preprocess(faithdial_dataset[\"train\"]), PROJECT_ROOT + \"data/faithdial_dataset_train.json\")\n","dump_as_json(critic_preprocess(faithdial_dataset[\"validation\"]), PROJECT_ROOT + \"data/faithdial_dataset_validation.json\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"V0aO873yQUqo"},"outputs":[],"source":["# fields = {\"knowledge\": (\"k\", KNOWLEDGE), \"response\": (\"r\", RESPONSE), \"hallucination\": (\"l\", LABEL), \"history\": (\"h\", HISTORY)}\n","fields = {\"all\": (\"a\", ALL), \"hallucination\": (\"l\", LABEL)}\n","\n","dataset = data.TabularDataset.splits(path=PROJECT_ROOT + \"data\",\n","                                     train=\"faithdial_dataset_train.json\",\n","                                     validation=\"faithdial_dataset_validation.json\",\n","                                     test=\"faithdial_dataset_test.json\",\n","                                     format=\"json\",\n","                                     fields=fields)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wpa0b_BcQUqo"},"outputs":[],"source":["train_data, valid_data, test_data = dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CB3RjeFzQUqo","executionInfo":{"status":"ok","timestamp":1682956863847,"user_tz":240,"elapsed":39,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}},"outputId":"89e907e2-b104-436e-b007-0b81294b6af5"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torchtext.data.example.Example at 0x7f7290f02500>"]},"metadata":{},"execution_count":62}],"source":["train_data[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CUIjXBl-QUqp","executionInfo":{"status":"ok","timestamp":1682956863847,"user_tz":240,"elapsed":34,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}},"outputId":"f4657f3b-0bf0-4669-dd19-c6c5c9374eb4"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'a': [101,\n","  2064,\n","  2017,\n","  5674,\n","  1996,\n","  2088,\n","  2302,\n","  4274,\n","  3229,\n","  1029,\n","  1026,\n","  1041,\n","  2891,\n","  1028,\n","  4274,\n","  3229,\n","  2001,\n","  2320,\n","  4678,\n","  1010,\n","  2021,\n","  2038,\n","  4961,\n","  5901,\n","  1012,\n","  1026,\n","  1041,\n","  2891,\n","  1028,\n","  2053,\n","  1045,\n","  2071,\n","  2025,\n","  999,\n","  1045,\n","  2481,\n","  1005,\n","  1056,\n","  5674,\n","  2542,\n","  2043,\n","  4274,\n","  3229,\n","  2001,\n","  4678,\n","  1998,\n","  2200,\n","  2261,\n","  2111,\n","  2018,\n","  2009,\n","  999,\n","  102],\n"," 'l': 'yes'}"]},"metadata":{},"execution_count":63}],"source":["vars(train_data.examples[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lD7OVfyOQUqp"},"outputs":[],"source":["if MODEL_CONFIG == \"LSTM\":\n","    MAX_VOCAB_SIZE = 25_000\n","    \n","    KNOWLEDGE.build_vocab(train_data,\n","                        max_size=MAX_VOCAB_SIZE,\n","                        vectors=\"fasttext.simple.300d\",\n","                        unk_init=torch.Tensor.normal_)\n","    RESPONSE.build_vocab(train_data,\n","                        max_size=MAX_VOCAB_SIZE,\n","                        vectors=\"fasttext.simple.300d\",\n","                        unk_init=torch.Tensor.normal_)\n","    HISTORY.build_vocab(train_data,\n","                        max_size=MAX_VOCAB_SIZE,\n","                        vectors=\"fasttext.simple.300d\",\n","                        unk_init=torch.Tensor.normal_)\n","    LABEL.build_vocab(train_data)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A7vOcX_PlasQ"},"outputs":[],"source":["if MODEL_CONFIG == \"BERT\":\n","    # vocab already built -- don't need to do anything except for labels\n","    LABEL.build_vocab(train_data)\n","    pass"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zBEl747NQUqp","executionInfo":{"status":"ok","timestamp":1682956863848,"user_tz":240,"elapsed":32,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}},"outputId":"52875a77-c9a6-4ef3-d8b6-028f3c6e063c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Unique tokens in LABEL vocabulary: 2\n"]}],"source":["# print(f\"Unique tokens in KNOWLEDGE vocabulary: {len(KNOWLEDGE.vocab)}\")\n","# print(f\"Unique tokens in RESPONSE vocabulary: {len(RESPONSE.vocab)}\")\n","# print(f\"Unique tokens in HISTORY vocabulary: {len(HISTORY.vocab)}\")\n","print(f\"Unique tokens in LABEL vocabulary: {len(LABEL.vocab)}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oYD0okYXQUqp","executionInfo":{"status":"ok","timestamp":1682956863848,"user_tz":240,"elapsed":30,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}},"outputId":"5588f3b5-8c83-4567-f6b1-a6b7daffa398"},"outputs":[{"output_type":"stream","name":"stdout","text":["[('no', 20474), ('yes', 13507)]\n"]}],"source":["# print(KNOWLEDGE.vocab.freqs.most_common(20))\n","# print(RESPONSE.vocab.freqs.most_common(20))\n","# print(HISTORY.vocab.freqs.most_common(20))\n","print(LABEL.vocab.freqs.most_common(20))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ulp3hp87QUqq","executionInfo":{"status":"ok","timestamp":1682956863848,"user_tz":240,"elapsed":28,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}},"outputId":"a14d6e53-d1dd-4939-f540-6c7abb37f1b2"},"outputs":[{"output_type":"stream","name":"stdout","text":["['no', 'yes']\n"]}],"source":["# print(KNOWLEDGE.vocab.itos[:10])\n","# print(RESPONSE.vocab.itos[:10])\n","# print(HISTORY.vocab.itos[:10])\n","print(LABEL.vocab.itos[:10])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vTvVnXnvQUqq"},"outputs":[],"source":["BATCH_SIZE = 8\n","\n","train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n","    (train_data, valid_data, test_data),\n","    batch_size = BATCH_SIZE,\n","    sort_within_batch = True,\n","    sort_key = lambda x: x.a,\n","    device = device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4NPgijQBQUqq"},"outputs":[],"source":["from torch import nn\n","\n","class LSTM(nn.Module):\n","    def __init__(self, response_vocab_size, knowledge_vocab_size, history_vocab_size, embedding_dim, hidden_dim, output_dim, n_layers,\n","                 bidirectional, dropout, response_pad_idx, knowledge_pad_idx, history_pad_idx):\n","\n","        super().__init__()\n","\n","        # Initialize Embedding Layer\n","        self.response_embedding = nn.Embedding(num_embeddings=response_vocab_size,\n","                                               embedding_dim=embedding_dim,\n","                                               padding_idx=response_pad_idx)\n","\n","        self.knowledge_embedding = nn.Embedding(num_embeddings=knowledge_vocab_size,\n","                                                embedding_dim=embedding_dim,\n","                                                padding_idx=knowledge_pad_idx)\n","        \n","        self.history_embedding = nn.Embedding(num_embeddings=history_vocab_size,\n","                                              embedding_dim=embedding_dim,\n","                                              padding_idx=history_pad_idx)\n","\n","        # Initialize LSTM layer\n","        self.response_lstm = nn.LSTM(input_size=embedding_dim,\n","                                     hidden_size=hidden_dim,\n","                                     num_layers=n_layers,\n","                                     bidirectional=bidirectional)\n","\n","        self.knowledge_lstm = nn.LSTM(input_size=embedding_dim,\n","                                      hidden_size=hidden_dim,\n","                                      num_layers=n_layers,\n","                                      bidirectional=bidirectional)\n","        \n","        self.history_lstm = nn.LSTM(input_size=embedding_dim,\n","                                    hidden_size=hidden_dim,\n","                                    num_layers=n_layers,\n","                                    bidirectional=bidirectional)\n","\n","        # Initialize a fully connected layer with Linear transformation\n","        self.fc = nn.Linear(in_features=3*2*hidden_dim,\n","                            out_features=output_dim)\n","\n","        # Initialize Dropout\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, response, response_lengths, knowledge, knowledge_lengths, history, history_lengths):\n","        # Apply embedding layer that matches each word to its vector and apply dropout. Dim [sent_len, batch_size, emb_dim]\n","        x_r = self.response_embedding(response)\n","        x_r = self.dropout(x_r)\n","\n","        x_k = self.knowledge_embedding(knowledge)\n","        x_k = self.dropout(x_k)\n","\n","        x_h = self.history_embedding(history)\n","        x_h = self.dropout(x_h)\n","\n","        # Run the LSTM along the sentences of length sent_len.\n","        output_r, (hidden_r, cell_r) = self.response_lstm(x_r)\n","        output_k, (hidden_k, cell_k) = self.knowledge_lstm(x_k)\n","        output_h, (hidden_h, cell_h) = self.history_lstm(x_h)\n","\n","        # Concat the final forward (hidden[-2,:,:]) and backward (hidden[-1,:,:]) hidden layers and apply dropout\n","        hidden_r = torch.cat((hidden_r[-2,:,:], hidden_r[-1,:,:]), -1)\n","        hidden_k = torch.cat((hidden_k[-2,:,:], hidden_k[-1,:,:]), -1)\n","        hidden_h = torch.cat((hidden_h[-2,:,:], hidden_h[-1,:,:]), -1)\n","        hidden = torch.cat((hidden_r, hidden_k, hidden_h), -1)\n","        hidden = self.dropout(hidden)\n","\n","        return self.fc(hidden)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"26V7ArBSBIRX"},"outputs":[],"source":["from torch import nn\n","import transformers\n","\n","class Transformer(nn.Module):\n","    def __init__(self, output_dim, dropout):\n","\n","        super().__init__()\n","\n","        # Bert layer\n","        config = transformers.BertConfig.from_pretrained(\"google/bert_uncased_L-4_H-256_A-4\")\n","        self.bert = transformers.BertModel.from_pretrained(\"google/bert_uncased_L-4_H-256_A-4\")\n","\n","        # Fully Connected Layer\n","        self.fc = nn.Linear(in_features=config.hidden_size,\n","                            out_features=output_dim)\n","\n","        # Dropout\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, all, all_lengths):\n","        # swap LENGTH and BATCH_SIZE dimensions\n","        x = torch.reshape(all, (all.shape[1], all.shape[0]))\n","        \n","        o = self.bert(x).pooler_output\n","        h = self.dropout(o)\n","\n","        return self.fc(h)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QI-pxfr1QUqq"},"outputs":[],"source":["# use original LSTM\n","if MODEL_CONFIG == \"LSTM\":\n","    RESPONSE_INPUT_DIM = len(RESPONSE.vocab)\n","    KNOWLEDGE_INPUT_DIM = len(KNOWLEDGE.vocab)\n","    HISTORY_INPUT_DIM = len(HISTORY.vocab)\n","    EMBEDDING_DIM = 300\n","    HIDDEN_DIM = 256\n","    OUTPUT_DIM = 1\n","    N_LAYERS = 2\n","    BIDIRECTIONAL = True\n","    DROPOUT = 0.5\n","    RESPONSE_PAD_IDX = RESPONSE.vocab.stoi[RESPONSE.pad_token]\n","    KNOWLEDGE_PAD_IDX = KNOWLEDGE.vocab.stoi[KNOWLEDGE.pad_token]\n","    HISTORY_PAD_IDX = HISTORY.vocab.stoi[HISTORY.pad_token]\n","    \n","    model = LSTM(RESPONSE_INPUT_DIM,\n","                KNOWLEDGE_INPUT_DIM,\n","                HISTORY_INPUT_DIM,\n","                EMBEDDING_DIM,\n","                HIDDEN_DIM,\n","                OUTPUT_DIM,\n","                N_LAYERS,\n","                BIDIRECTIONAL,\n","                DROPOUT,\n","                RESPONSE_PAD_IDX,\n","                KNOWLEDGE_PAD_IDX,\n","                HISTORY_PAD_IDX)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RNT1jdMNAMgH","executionInfo":{"status":"ok","timestamp":1682956863850,"user_tz":240,"elapsed":28,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}},"outputId":"a82920ca-947a-4dd1-bfab-10266442b3bf"},"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at google/bert_uncased_L-4_H-256_A-4 were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}],"source":["if MODEL_CONFIG == \"BERT\":\n","    OUTPUT_DIM=1\n","    DROPOUT = 0.5\n","    model = Transformer(OUTPUT_DIM, DROPOUT) "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IyXNhzOfQUqr","executionInfo":{"status":"ok","timestamp":1682956863850,"user_tz":240,"elapsed":26,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}},"outputId":"45596047-ac72-479b-9e85-98e6020b493b"},"outputs":[{"output_type":"stream","name":"stdout","text":["The model has 11,170,817 trainable parameters\n"]}],"source":["def count_parameters(model):\n","    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n","\n","print(f'The model has {count_parameters(model):,} trainable parameters')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M5QN73gYQUqr"},"outputs":[],"source":["# print(RESPONSE.vocab.vectors.shape)\n","# print(KNOWLEDGE.vocab.vectors.shape)\n","# print(HISTORY.vocab.vectors.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x36lpus-QUqr"},"outputs":[],"source":["if MODEL_CONFIG == \"LSTM\":\n","    model.response_embedding.weight.data.copy_(RESPONSE.vocab.vectors)\n","    model.knowledge_embedding.weight.data.copy_(KNOWLEDGE.vocab.vectors)\n","    model.history_embedding.weight.data.copy_(HISTORY.vocab.vectors)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wxxPbBUIQUqr"},"outputs":[],"source":["if MODEL_CONFIG == \"LSTM\":\n","    UNK_IDX_R = RESPONSE.vocab.stoi[RESPONSE.unk_token]\n","    UNK_IDX_K = RESPONSE.vocab.stoi[KNOWLEDGE.unk_token]\n","    UNK_IDX_H = RESPONSE.vocab.stoi[HISTORY.unk_token]\n","\n","    model.response_embedding.weight.data[UNK_IDX_R] = torch.zeros(EMBEDDING_DIM)\n","    model.response_embedding.weight.data[RESPONSE_PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n","\n","    model.knowledge_embedding.weight.data[UNK_IDX_K] = torch.zeros(EMBEDDING_DIM)\n","    model.knowledge_embedding.weight.data[KNOWLEDGE_PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n","\n","    model.history_embedding.weight.data[UNK_IDX_H] = torch.zeros(EMBEDDING_DIM)\n","    model.history_embedding.weight.data[HISTORY_PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n","\n","    print(model.response_embedding.weight.data)\n","    print(model.knowledge_embedding.weight.data)\n","    print(model.history_embedding.weight.data)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qbo5y26lQUqr"},"outputs":[],"source":["import torch.optim as optim\n","\n","optimizer = optim.Adam(model.parameters())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p1jpbDlCQUqs"},"outputs":[],"source":["criterion = nn.BCEWithLogitsLoss()\n","\n","model = model.to(device)\n","criterion = criterion.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EeefTt3RQUqs"},"outputs":[],"source":["from sklearn.metrics import f1_score\n","\n","\n","def binary_accuracy(preds, y):\n","    \"\"\"\n","    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n","    \"\"\"\n","    #round predictions to the closest integer\n","    rounded_preds = torch.round(torch.sigmoid(preds))\n","    correct = (rounded_preds == y).float() #convert into float for division \n","    acc = correct.sum() / len(correct)\n","    return acc\n","\n","\n","def binary_f1(preds, y):\n","    rounded_preds = torch.round(torch.sigmoid(preds))\n","    f1 = f1_score(y.cpu(), rounded_preds.cpu(), average=\"macro\")\n","    return f1\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"syBOhKqsQUqs"},"outputs":[],"source":["def train(model, iterator, optimizer, criterion):\n","\n","    epoch_loss = 0\n","    epoch_acc = 0\n","\n","    model.train()\n","\n","    for batch in iterator:\n","\n","        optimizer.zero_grad()\n","\n","        all, lengths = batch.a\n","        predictions = model(all, lengths).squeeze(1)\n","\n","        loss = criterion(predictions, batch.l)\n","\n","        acc = binary_accuracy(predictions, batch.l)\n","\n","        loss.backward()\n","\n","        optimizer.step()\n","\n","        epoch_loss += loss.item()\n","        epoch_acc += acc.item()\n","\n","    return epoch_loss / len(iterator), epoch_acc / len(iterator)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LU-Fvt9JQUqs"},"outputs":[],"source":["def evaluate(model, iterator, criterion):\n","\n","    epoch_loss = 0\n","    epoch_acc = 0\n","    epoch_f1 = 0\n","\n","    model.eval()\n","\n","    with torch.no_grad():\n","\n","        for batch in iterator:\n","            all, lengths = batch.a\n","            predictions = model(all, lengths).squeeze(1)\n","\n","            loss = criterion(predictions, batch.l)\n","            acc = binary_accuracy(predictions, batch.l)\n","            f1 = binary_f1(predictions, batch.l)\n","\n","            epoch_loss += loss.item()\n","            epoch_acc += acc.item()\n","            epoch_f1 += f1.item()\n","\n","    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_f1 / len(iterator)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lMpGhV9jQUqs"},"outputs":[],"source":["import time\n","\n","def epoch_time(start_time, end_time):\n","    elapsed_time = end_time - start_time\n","    elapsed_mins = int(elapsed_time / 60)\n","    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n","    return elapsed_mins, elapsed_secs"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1asXdkH-QUqs","executionInfo":{"status":"ok","timestamp":1682957406868,"user_tz":240,"elapsed":543038,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}},"outputId":"4492439b-01c5-4cd8-e376-f434e659fd44"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 01 | Epoch Time: 1m 48s\n","\tTrain Loss: 6.711 | Train Acc: 43.49% |\n","\t Val. Loss: 6.645 |  Val. Acc: 40.00% | Val. F1: 0.280\n","Epoch: 02 | Epoch Time: 1m 49s\n","\tTrain Loss: 6.696 | Train Acc: 39.76% |\n","\t Val. Loss: 6.645 |  Val. Acc: 40.00% | Val. F1: 0.280\n","Epoch: 03 | Epoch Time: 1m 48s\n","\tTrain Loss: 6.693 | Train Acc: 39.75% |\n","\t Val. Loss: 6.645 |  Val. Acc: 40.00% | Val. F1: 0.280\n","Epoch: 04 | Epoch Time: 1m 47s\n","\tTrain Loss: 6.696 | Train Acc: 39.75% |\n","\t Val. Loss: 6.645 |  Val. Acc: 40.00% | Val. F1: 0.280\n","Epoch: 05 | Epoch Time: 1m 48s\n","\tTrain Loss: 6.698 | Train Acc: 39.75% |\n","\t Val. Loss: 6.645 |  Val. Acc: 40.00% | Val. F1: 0.280\n"]}],"source":["N_EPOCHS = 5\n","# path = F\"/content/gdrive/My Drive/bilstm_model.pt\"\n","path = PROJECT_ROOT + F\"/bert_concat_model.pt\"\n","best_valid_loss = float('inf')\n","\n","for epoch in range(N_EPOCHS):\n","\n","    start_time = time.time()\n","\n","    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n","    valid_loss, valid_acc, valid_f1 = evaluate(model, valid_iterator, criterion)\n","\n","    end_time = time.time()\n","\n","    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n","\n","    if valid_loss < best_valid_loss:\n","        best_valid_loss = valid_loss\n","        torch.save(model.state_dict(), path)\n","\n","    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n","    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}% |')\n","    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}% | Val. F1: {valid_f1:.3f}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t5aHFK_HQUqs","executionInfo":{"status":"ok","timestamp":1682957413779,"user_tz":240,"elapsed":6914,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"42b87c1e-d47c-4f6f-a229-1df6b16a361e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Test Loss: 6.590 | Test Acc: 39.63% | Test F1: 0.28\n"]}],"source":["model.load_state_dict(torch.load(path, map_location=device))\n","\n","test_loss, test_acc, test_f1 = evaluate(model, test_iterator, criterion)\n","\n","print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}% | Test F1: {test_f1:.2f}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iOoouH7OUMHJ"},"outputs":[],"source":["import spacy\n","nlp = spacy.load('en_core_web_sm')\n","\n","def predict_hallucination(model, knowledge, response):\n","    model.eval()\n","\n","    tokenized_r = [tok.text for tok in nlp.tokenizer(response)]\n","    indexed_r = [RESPONSE.vocab.stoi[t] for t in tokenized_r]\n","    length_r = [len(indexed_r)]\n","    tensor_r = torch.LongTensor(indexed_r).to(device)\n","    tensor_r = tensor_r.unsqueeze(1)\n","    length_tensor_r = torch.LongTensor(length_r)\n","\n","    tokenized_k = [tok.text for tok in nlp.tokenizer(knowledge)]\n","    indexed_k = [KNOWLEDGE.vocab.stoi[t] for t in tokenized_k]\n","    length_k = [len(indexed_k)]\n","    tensor_k = torch.LongTensor(indexed_k).to(device)\n","    tensor_k = tensor_k.unsqueeze(1)\n","    length_tensor_k = torch.LongTensor(length_k)\n","\n","    prediction = torch.sigmoid(model(tensor_r, length_tensor_r, tensor_k, length_tensor_k))\n","\n","    return prediction.item()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uCFZFBo1U3MO","executionInfo":{"status":"error","timestamp":1682957415176,"user_tz":240,"elapsed":16,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}},"colab":{"base_uri":"https://localhost:8080/","height":433},"outputId":"3f129610-de46-4968-a000-936ae8f0e6c7"},"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-87-24053f06acd2>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredict_hallucination\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"I love dogs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-86-d7b7bc3a242a>\u001b[0m in \u001b[0;36mpredict_hallucination\u001b[0;34m(model, knowledge, response)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mtokenized_r\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtok\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtok\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mindexed_r\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mRESPONSE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstoi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokenized_r\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mlength_r\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexed_r\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mtensor_r\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexed_r\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-86-d7b7bc3a242a>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mtokenized_r\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtok\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtok\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mindexed_r\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mRESPONSE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstoi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokenized_r\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mlength_r\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexed_r\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mtensor_r\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexed_r\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'RESPONSE' is not defined"]}],"source":["predict_hallucination(model, \"\", \"I love dogs\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f0LU-GstVIog"},"outputs":[],"source":["predict_hallucination(model, \"\", \"Dogs are animals.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8HpFk6G2VLmU"},"outputs":[],"source":["predict_hallucination(model, \"\", \"I was walking my dog last week.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_ZH_nqk6VQbP"},"outputs":[],"source":["predict_hallucination(model, \"\", \"Dogs need to be walked daily.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hxV02zIwVYkH"},"outputs":[],"source":["test_data[2].r"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nytN5bp8Vkpk"},"outputs":[],"source":["predict_hallucination(model, \"\", \"Dylan's Candy Bar is a candy supplier.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vTT3ALVCVtm0"},"outputs":[],"source":["predict_hallucination(model, \"\", \"Dylan's Candy Bar is my favorite great brand of candy.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-YUZpBhDFrXq"},"outputs":[],"source":["print(test_data[2].h)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K1h-8pHEF01y"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xt89YaAt-b8G"},"outputs":[],"source":["# test BERT\n","test_tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n","test_model = BertModel.from_pretrained(\"bert-base-uncased\")\n","\n","inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1mJQOjuU_CuE"},"outputs":[],"source":["inputs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"17uFL4D__DZz"},"outputs":[],"source":["outputs = test_model(**inputs)\n","outputs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zFjqCu5U_F6T"},"outputs":[],"source":["outputs = model(inputs[\"input_ids\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wwXpdfbV_6E3"},"outputs":[],"source":["outputs[\"pooler_output\"][0].squeeze(-1)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rC1UOM3eA2y9"},"outputs":[],"source":["outputs[\"pooler_output\"].squeeze(-1).size()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7x0cD6quA5c8"},"outputs":[],"source":["loss, output = model(inputs[\"input_ids\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7bHCTQGaBhrO"},"outputs":[],"source":["loss"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nGU3Kw1OBjRV"},"outputs":[],"source":["output"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uFWACOufJ5EK"},"outputs":[],"source":["import gc\n","model = None\n","torch.cuda.empty_cache()\n","gc.collect()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cDowqeO5J5al"},"outputs":[],"source":["test_model(inputs.input_ids).pooler_output.size()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2VKEyTE2KzMf"},"outputs":[],"source":["inputs.input_ids.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B7qH3XgvMSPg"},"outputs":[],"source":["torch.flip(inputs.input_ids, []).shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C1xh0fsOMk7f"},"outputs":[],"source":["torch.reshape(inputs.input_ids, (inputs.input_ids.shape[1], inputs.input_ids.shape[0])).shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wAL2MbIeNRxH"},"outputs":[],"source":["torch.reshape(inputs.input_ids, (inputs.input_ids.shape[1], inputs.input_ids.shape[0]))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wH7hj3ClNY8a"},"outputs":[],"source":["inputs.input_ids"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F6aDAU_ENcEd"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r8UuM5ZeNmsu"},"outputs":[],"source":["\n","BertTokenizer.from_pretrained(\"google/bert_uncased_L-4_H-256_A-4\")\n","BertModel.from_pretrained(\"google/bert_uncased_L-4_H-256_A-4\")\n","# BertTokenizer.from_pretrained(\"bert-tiny\")\n","# BertModel.from_pretrained(\"bert-tiny\")"]},{"cell_type":"code","source":[],"metadata":{"id":"6IwW94s-XhHA"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10"},"widgets":{"application/vnd.jupyter.widget-state+json":{"d97d97289b444b14b38a9bbd05050016":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_04d2cf009e92411e97f822d782f605e9","IPY_MODEL_f74b641a629e4c95918565a792df8152","IPY_MODEL_b588ab617cf540918875599b6efae288"],"layout":"IPY_MODEL_92f697c153524a459b03ce30f60de9eb"}},"04d2cf009e92411e97f822d782f605e9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_06e6e0ce405c4b6b85787f0663a69e65","placeholder":"​","style":"IPY_MODEL_888e8e3856ad4883ab9df5af715558c5","value":"100%"}},"f74b641a629e4c95918565a792df8152":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_890dd9bd07f8423887567924b3137b16","max":7,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2096639b36e24bf9badeb2d0a03548be","value":7}},"b588ab617cf540918875599b6efae288":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dbf8390f22d5469db5e55af024ade05e","placeholder":"​","style":"IPY_MODEL_cb4ed39537bb41158479a2e9a462aa9e","value":" 7/7 [00:00&lt;00:00, 186.91it/s]"}},"92f697c153524a459b03ce30f60de9eb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"06e6e0ce405c4b6b85787f0663a69e65":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"888e8e3856ad4883ab9df5af715558c5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"890dd9bd07f8423887567924b3137b16":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2096639b36e24bf9badeb2d0a03548be":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"dbf8390f22d5469db5e55af024ade05e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cb4ed39537bb41158479a2e9a462aa9e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}