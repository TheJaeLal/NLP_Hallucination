{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":40500,"status":"ok","timestamp":1683485939551,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"},"user_tz":240},"id":"JML6-VPnQUqh","outputId":"03b7cf2f-c4ac-46e9-ce58-e8c388661094"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting torchtext==0.6.0\n","  Downloading torchtext-0.6.0-py3-none-any.whl (64 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.2/64.2 kB\u001b[0m \u001b[31m312.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (2.27.1)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (2.0.0+cu118)\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (1.16.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (4.65.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (1.22.4)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (1.26.15)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (2.0.12)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (2022.12.7)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (3.4)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (3.1)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (2.0.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (1.11.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (3.12.0)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (3.1.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (4.5.0)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->torchtext==0.6.0) (16.0.2)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->torchtext==0.6.0) (3.25.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->torchtext==0.6.0) (2.1.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->torchtext==0.6.0) (1.3.0)\n","Installing collected packages: sentencepiece, torchtext\n","  Attempting uninstall: torchtext\n","    Found existing installation: torchtext 0.15.1\n","    Uninstalling torchtext-0.15.1:\n","      Successfully uninstalled torchtext-0.15.1\n","Successfully installed sentencepiece-0.1.99 torchtext-0.6.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting datasets\n","  Downloading datasets-2.12.0-py3-none-any.whl (474 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m474.6/474.6 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting huggingface-hub<1.0.0,>=0.11.0\n","  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting dill<0.3.7,>=0.3.0\n","  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting multiprocess\n","  Downloading multiprocess-0.70.14-py310-none-any.whl (134 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0)\n","Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n","Collecting responses<0.19\n","  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n","Collecting xxhash\n","  Downloading xxhash-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.5/212.5 kB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.65.0)\n","Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.4.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.22.4)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.27.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.1)\n","Collecting aiohttp\n","  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m48.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.0.12)\n","Collecting frozenlist>=1.1.1\n","  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting multidict<7.0,>=4.5\n","  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting aiosignal>=1.1.2\n","  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n","Collecting async-timeout<5.0,>=4.0.0a3\n","  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n","Collecting yarl<2.0,>=1.0\n","  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (3.12.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (4.5.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (1.26.15)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2022.7.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n","Installing collected packages: xxhash, multidict, frozenlist, dill, async-timeout, yarl, responses, multiprocess, huggingface-hub, aiosignal, aiohttp, datasets\n","Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 datasets-2.12.0 dill-0.3.6 frozenlist-1.3.3 huggingface-hub-0.14.1 multidict-6.0.4 multiprocess-0.70.14 responses-0.18.0 xxhash-3.2.0 yarl-1.9.2\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m82.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m108.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.14.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (2023.4.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n","Installing collected packages: tokenizers, transformers\n","Successfully installed tokenizers-0.13.3 transformers-4.28.1\n"]}],"source":["! pip install torchtext==0.6.0\n","# ! pip install torchtext==0.12.0\n","! pip install datasets\n","! pip install transformers"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lKGVdP7VAlG2","executionInfo":{"status":"ok","timestamp":1683485967350,"user_tz":240,"elapsed":27803,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}},"outputId":"923546ad-9429-4661-9085-8f3805943f11"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","execution_count":84,"metadata":{"id":"EDgQMtgJQfdJ","executionInfo":{"status":"ok","timestamp":1683487588473,"user_tz":240,"elapsed":300,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}}},"outputs":[],"source":["from datasets import load_dataset\n","\n","# from transformers import BertTokenizer, BertModel, BertConfig\n","from transformers import AutoTokenizer, AutoModel, AutoConfig\n","\n","import torch\n","# from torchtext.legacy import data\n","from torchtext import data"]},{"cell_type":"code","execution_count":85,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pyyXY3Y9CJyB","executionInfo":{"status":"ok","timestamp":1683487590051,"user_tz":240,"elapsed":418,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}},"outputId":"4347ecc9-130d-48b1-a861-10627d880a95"},"outputs":[{"output_type":"stream","name":"stdout","text":["Using MODEL_CONFIG BERT\n"]}],"source":["# choose configurations for the model\n","# MODEL_CONFIG=\"LSTM\"\n","MODEL_CONFIG=\"BERT\"\n","# BERT_TYPE=\"google/bert_uncased_L-4_H-256_A-4\"\n","BERT_TYPE=\"prajjwal1/bert-tiny\"\n","\n","print(\"Using MODEL_CONFIG\", MODEL_CONFIG)"]},{"cell_type":"code","execution_count":86,"metadata":{"id":"0zHpR9aKRA5F","executionInfo":{"status":"ok","timestamp":1683487590052,"user_tz":240,"elapsed":8,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}}},"outputs":[],"source":["PROJECT_ROOT = F\"/content/gdrive/My Drive/nlp_project_task_1_BERT/\"\n","                                          "]},{"cell_type":"code","execution_count":87,"metadata":{"id":"ZHwitHvFQUqk","executionInfo":{"status":"ok","timestamp":1683487590052,"user_tz":240,"elapsed":7,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}}},"outputs":[],"source":["SEED = 42"]},{"cell_type":"code","execution_count":88,"metadata":{"id":"BS_qqwWkQUqk","executionInfo":{"status":"ok","timestamp":1683487590052,"user_tz":240,"elapsed":7,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}}},"outputs":[],"source":["torch.manual_seed(SEED)\n","torch.backends.cudnn.deterministic = True"]},{"cell_type":"code","execution_count":89,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ztb4YGEIQUql","executionInfo":{"status":"ok","timestamp":1683487590053,"user_tz":240,"elapsed":8,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}},"outputId":"8c963ff4-9a4c-4ff1-c5d5-0eb5a7df0682"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda')"]},"metadata":{},"execution_count":89}],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","device"]},{"cell_type":"code","execution_count":90,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":84,"referenced_widgets":["5e3be46752e8494dbf51fa8d9695d807","d99107d8fede42e6bef0d1bd1e794d36","72db936feb8d4687a251baf1029862c3","93bebb19189b4c74ae68ba80c1d8be7b","ee27e19b5b1e4740920b68e9ab8b2777","5f45693cbc05457abcfa1b401ae3479a","ec6539ce123640b880e40c7378281495","70e33e52e55f455d8d77f3febb4a7a2a","ee9b11c7675d41abb5d75fc6dbdb365b","54648151c7cd4df698a3880d5aa8c207","02d6c9d1fff64a5fbea5d24f45426dcc"]},"id":"REBQaOuFQUql","executionInfo":{"status":"ok","timestamp":1683487591734,"user_tz":240,"elapsed":1686,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}},"outputId":"7f61d493-c132-4102-b59e-6fd1968e4b90"},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:datasets.builder:No config specified, defaulting to: faith_dial/plain_text\n","WARNING:datasets.builder:Found cached dataset faith_dial (/root/.cache/huggingface/datasets/McGill-NLP___faith_dial/plain_text/1.0.0/70568c8ab3bbc83b603bce58fa593ab27e7f0d0cde51034e1c2073ff3e14189a)\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/7 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5e3be46752e8494dbf51fa8d9695d807"}},"metadata":{}}],"source":["faithdial_dataset = load_dataset(\"McGill-NLP/FaithDial\")"]},{"cell_type":"code","execution_count":91,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"juF-GfX5QUqm","executionInfo":{"status":"ok","timestamp":1683487591734,"user_tz":240,"elapsed":10,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}},"outputId":"3b6c3958-5d9f-4978-f3fb-a90a595a049c"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["dict_keys(['test', 'test_random_split', 'test_topic_split', 'train', 'validation', 'valid_random_split', 'valid_topic_split'])"]},"metadata":{},"execution_count":91}],"source":["faithdial_dataset.keys()"]},{"cell_type":"code","execution_count":92,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IzV6pQ3O3WLj","executionInfo":{"status":"ok","timestamp":1683487591735,"user_tz":240,"elapsed":9,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}},"outputId":"4eaeee8c-9fb4-4524-e203-8aea1583fe1c"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'dialog_idx': 0,\n"," 'response': 'Yeah, but once the access to the internet was a rare thing. do you remember?',\n"," 'original_response': \"No I could not! I couldn't imagine living when internet access was rare and very few people had it!\",\n"," 'history': ['Can you imagine the world without internet access?'],\n"," 'knowledge': 'Internet access was once rare, but has grown rapidly.',\n"," 'BEGIN': ['Hallucination'],\n"," 'VRM': ['Disclosure', 'Ack.']}"]},"metadata":{},"execution_count":92}],"source":["faithdial_dataset[\"train\"][0]"]},{"cell_type":"code","execution_count":93,"metadata":{"id":"7aHU5_UXQUqm","executionInfo":{"status":"ok","timestamp":1683487591735,"user_tz":240,"elapsed":6,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}}},"outputs":[],"source":["def critic_preprocess(dataset):\n","    \"\"\"\n","    Data items transformed into (knowledge, response, is_hallucination)\n","    \"\"\"\n","    new_dataset = []\n","    for d in dataset:\n","        # original response\n","        if d[\"original_response\"] != None:\n","            new_dataset.append({\n","                \"knowledge\": d[\"knowledge\"],\n","                \"response\": d[\"original_response\"],\n","                \"hallucination\": \"yes\" if \"Hallucination\" in d[\"BEGIN\"] else \"no\",\n","                \"history\": \" \".join(d[\"history\"]) # separate histories by ' '\n","                                                  # (i.e., will be a seq of sentences)\n","            })\n","\n","        # new responses always aren't hallucinations\n","        new_dataset.append({\"knowledge\": d[\"knowledge\"], \"response\": d[\"response\"], \"hallucination\": \"no\", \"history\": \"\\\\\".join(d[\"history\"])})\n","    return new_dataset"]},{"cell_type":"code","execution_count":94,"metadata":{"id":"NvX3XmUGQUqn","executionInfo":{"status":"ok","timestamp":1683487591735,"user_tz":240,"elapsed":6,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}}},"outputs":[],"source":["import json\n","\n","def dump_as_json(dataset, filename):\n","    \"\"\"\n","    Takes a list of dicts and dumps it as a json file that torchtext can parse.\n","    \"\"\"\n","    with open(filename, \"w\") as file:\n","        for d in dataset:\n","            file.write(json.dumps(d))\n","            file.write(\"\\n\")\n"]},{"cell_type":"code","execution_count":95,"metadata":{"id":"lprbGYNEQUqn","executionInfo":{"status":"ok","timestamp":1683487591736,"user_tz":240,"elapsed":6,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}}},"outputs":[],"source":["if MODEL_CONFIG == \"LSTM\":\n","    KNOWLEDGE = data.Field(tokenize='spacy', tokenizer_language=\"en_core_web_sm\", include_lengths=True)\n","    RESPONSE = data.Field(tokenize='spacy', tokenizer_language=\"en_core_web_sm\", include_lengths=True)\n","    HISTORY = data.Field(tokenize='spacy', tokenizer_language=\"en_core_web_sm\", include_lengths=True)\n","    LABEL = data.LabelField(dtype=torch.float)"]},{"cell_type":"code","execution_count":96,"metadata":{"id":"Fpsa29Dknhhs","executionInfo":{"status":"ok","timestamp":1683487592926,"user_tz":240,"elapsed":1196,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}}},"outputs":[],"source":["if MODEL_CONFIG == \"BERT\":\n","    tokenizer = AutoTokenizer.from_pretrained('google/bert_uncased_L-4_H-256_A-4', do_lower_case=True)\n","    pad_index = tokenizer.convert_tokens_to_ids(tokenizer.pad_token)\n","    unk_index = tokenizer.convert_tokens_to_ids(tokenizer.unk_token)\n","\n","    KNOWLEDGE = data.Field(use_vocab=False,\n","                            tokenize=tokenizer.encode,\n","                            pad_token=pad_index,\n","                            unk_token=unk_index,\n","                            include_lengths = True)\n","    RESPONSE = data.Field(use_vocab=False,\n","                          tokenize=tokenizer.encode,\n","                          pad_token=pad_index,\n","                          unk_token=unk_index,\n","                          include_lengths=True)\n","    HISTORY = data.Field(use_vocab=False,\n","                         tokenize=tokenizer.encode,\n","                         pad_token=pad_index,\n","                         unk_token=unk_index,\n","                         include_lengths=True)\n","    LABEL = data.LabelField(dtype=torch.float)"]},{"cell_type":"code","execution_count":97,"metadata":{"id":"h-8aVlf5QUqn","executionInfo":{"status":"ok","timestamp":1683487595312,"user_tz":240,"elapsed":2389,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}}},"outputs":[],"source":["dump_as_json(critic_preprocess(faithdial_dataset[\"test\"]), PROJECT_ROOT + \"data/faithdial_dataset_test.json\")\n","dump_as_json(critic_preprocess(faithdial_dataset[\"train\"]), PROJECT_ROOT + \"data/faithdial_dataset_train.json\")\n","dump_as_json(critic_preprocess(faithdial_dataset[\"validation\"]), PROJECT_ROOT + \"data/faithdial_dataset_validation.json\")"]},{"cell_type":"code","execution_count":98,"metadata":{"id":"V0aO873yQUqo","executionInfo":{"status":"ok","timestamp":1683487627658,"user_tz":240,"elapsed":32347,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}}},"outputs":[],"source":["fields = {\"knowledge\": (\"k\", KNOWLEDGE), \"response\": (\"r\", RESPONSE), \"hallucination\": (\"l\", LABEL), \"history\": (\"h\", HISTORY)}\n","\n","dataset = data.TabularDataset.splits(path=PROJECT_ROOT + \"data\",\n","                                     train=\"faithdial_dataset_train.json\",\n","                                     validation=\"faithdial_dataset_validation.json\",\n","                                     test=\"faithdial_dataset_test.json\",\n","                                     format=\"json\",\n","                                     fields=fields)\n"]},{"cell_type":"code","execution_count":99,"metadata":{"id":"wpa0b_BcQUqo","executionInfo":{"status":"ok","timestamp":1683487627659,"user_tz":240,"elapsed":20,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}}},"outputs":[],"source":["train_data, valid_data, test_data = dataset"]},{"cell_type":"code","execution_count":100,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CB3RjeFzQUqo","executionInfo":{"status":"ok","timestamp":1683487627659,"user_tz":240,"elapsed":20,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}},"outputId":"88ad5145-18cc-4011-a0ab-85788f220437"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torchtext.data.example.Example at 0x7f85552312a0>"]},"metadata":{},"execution_count":100}],"source":["train_data[0]"]},{"cell_type":"code","execution_count":101,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CUIjXBl-QUqp","executionInfo":{"status":"ok","timestamp":1683487627659,"user_tz":240,"elapsed":18,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}},"outputId":"5da9cb85-5a23-4c6f-dce1-da9b7b38865f"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'k': [101,\n","  4274,\n","  3229,\n","  2001,\n","  2320,\n","  4678,\n","  1010,\n","  2021,\n","  2038,\n","  4961,\n","  5901,\n","  1012,\n","  102],\n"," 'r': [101,\n","  2053,\n","  1045,\n","  2071,\n","  2025,\n","  999,\n","  1045,\n","  2481,\n","  1005,\n","  1056,\n","  5674,\n","  2542,\n","  2043,\n","  4274,\n","  3229,\n","  2001,\n","  4678,\n","  1998,\n","  2200,\n","  2261,\n","  2111,\n","  2018,\n","  2009,\n","  999,\n","  102],\n"," 'l': 'yes',\n"," 'h': [101, 2064, 2017, 5674, 1996, 2088, 2302, 4274, 3229, 1029, 102]}"]},"metadata":{},"execution_count":101}],"source":["vars(train_data.examples[0])"]},{"cell_type":"code","execution_count":102,"metadata":{"id":"lD7OVfyOQUqp","executionInfo":{"status":"ok","timestamp":1683487627660,"user_tz":240,"elapsed":16,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}}},"outputs":[],"source":["if MODEL_CONFIG == \"LSTM\":\n","    MAX_VOCAB_SIZE = 25_000\n","    \n","    KNOWLEDGE.build_vocab(train_data,\n","                        max_size=MAX_VOCAB_SIZE,\n","                        vectors=\"fasttext.simple.300d\",\n","                        unk_init=torch.Tensor.normal_)\n","    RESPONSE.build_vocab(train_data,\n","                        max_size=MAX_VOCAB_SIZE,\n","                        vectors=\"fasttext.simple.300d\",\n","                        unk_init=torch.Tensor.normal_)\n","    HISTORY.build_vocab(train_data,\n","                        max_size=MAX_VOCAB_SIZE,\n","                        vectors=\"fasttext.simple.300d\",\n","                        unk_init=torch.Tensor.normal_)\n","    LABEL.build_vocab(train_data)\n"]},{"cell_type":"code","execution_count":103,"metadata":{"id":"A7vOcX_PlasQ","executionInfo":{"status":"ok","timestamp":1683487627660,"user_tz":240,"elapsed":16,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}}},"outputs":[],"source":["if MODEL_CONFIG == \"BERT\":\n","    # vocab already built -- don't need to do anything except for labels\n","    LABEL.build_vocab(train_data)\n","    pass"]},{"cell_type":"code","execution_count":104,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zBEl747NQUqp","executionInfo":{"status":"ok","timestamp":1683487627661,"user_tz":240,"elapsed":16,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}},"outputId":"82ee4d84-2ceb-4976-c1fd-b1522bb4caf9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Unique tokens in LABEL vocabulary: 2\n"]}],"source":["# print(f\"Unique tokens in KNOWLEDGE vocabulary: {len(KNOWLEDGE.vocab)}\")\n","# print(f\"Unique tokens in RESPONSE vocabulary: {len(RESPONSE.vocab)}\")\n","# print(f\"Unique tokens in HISTORY vocabulary: {len(HISTORY.vocab)}\")\n","print(f\"Unique tokens in LABEL vocabulary: {len(LABEL.vocab)}\")"]},{"cell_type":"code","execution_count":105,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oYD0okYXQUqp","executionInfo":{"status":"ok","timestamp":1683487627661,"user_tz":240,"elapsed":13,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}},"outputId":"e766124d-5791-4a54-c59b-e93216408eb6"},"outputs":[{"output_type":"stream","name":"stdout","text":["[('no', 20474), ('yes', 13507)]\n"]}],"source":["# print(KNOWLEDGE.vocab.freqs.most_common(20))\n","# print(RESPONSE.vocab.freqs.most_common(20))\n","# print(HISTORY.vocab.freqs.most_common(20))\n","print(LABEL.vocab.freqs.most_common(20))"]},{"cell_type":"code","execution_count":106,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ulp3hp87QUqq","executionInfo":{"status":"ok","timestamp":1683487627661,"user_tz":240,"elapsed":10,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}},"outputId":"53166ee8-95d5-4721-ba78-df17d5d77100"},"outputs":[{"output_type":"stream","name":"stdout","text":["['no', 'yes']\n"]}],"source":["# print(KNOWLEDGE.vocab.itos[:10])\n","# print(RESPONSE.vocab.itos[:10])\n","# print(HISTORY.vocab.itos[:10])\n","print(LABEL.vocab.itos[:10])"]},{"cell_type":"code","execution_count":107,"metadata":{"id":"vTvVnXnvQUqq","executionInfo":{"status":"ok","timestamp":1683487627662,"user_tz":240,"elapsed":8,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}}},"outputs":[],"source":["BATCH_SIZE = 8\n","\n","train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n","    (train_data, valid_data, test_data),\n","    batch_size = BATCH_SIZE,\n","    sort_within_batch = True,\n","    sort_key = lambda x: x.r,\n","    device = device)"]},{"cell_type":"code","execution_count":108,"metadata":{"id":"4NPgijQBQUqq","executionInfo":{"status":"ok","timestamp":1683487627662,"user_tz":240,"elapsed":8,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}}},"outputs":[],"source":["from torch import nn\n","\n","class LSTM(nn.Module):\n","    def __init__(self, response_vocab_size, knowledge_vocab_size, history_vocab_size, embedding_dim, hidden_dim, output_dim, n_layers,\n","                 bidirectional, dropout, response_pad_idx, knowledge_pad_idx, history_pad_idx):\n","\n","        super().__init__()\n","\n","        # Initialize Embedding Layer\n","        self.response_embedding = nn.Embedding(num_embeddings=response_vocab_size,\n","                                               embedding_dim=embedding_dim,\n","                                               padding_idx=response_pad_idx)\n","\n","        self.knowledge_embedding = nn.Embedding(num_embeddings=knowledge_vocab_size,\n","                                                embedding_dim=embedding_dim,\n","                                                padding_idx=knowledge_pad_idx)\n","        \n","        self.history_embedding = nn.Embedding(num_embeddings=history_vocab_size,\n","                                              embedding_dim=embedding_dim,\n","                                              padding_idx=history_pad_idx)\n","\n","        # Initialize LSTM layer\n","        self.response_lstm = nn.LSTM(input_size=embedding_dim,\n","                                     hidden_size=hidden_dim,\n","                                     num_layers=n_layers,\n","                                     bidirectional=bidirectional)\n","\n","        self.knowledge_lstm = nn.LSTM(input_size=embedding_dim,\n","                                      hidden_size=hidden_dim,\n","                                      num_layers=n_layers,\n","                                      bidirectional=bidirectional)\n","        \n","        self.history_lstm = nn.LSTM(input_size=embedding_dim,\n","                                    hidden_size=hidden_dim,\n","                                    num_layers=n_layers,\n","                                    bidirectional=bidirectional)\n","\n","        # Initialize a fully connected layer with Linear transformation\n","        self.fc = nn.Linear(in_features=3*2*hidden_dim,\n","                            out_features=output_dim)\n","\n","        # Initialize Dropout\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, response, response_lengths, knowledge, knowledge_lengths, history, history_lengths):\n","        # Apply embedding layer that matches each word to its vector and apply dropout. Dim [sent_len, batch_size, emb_dim]\n","        x_r = self.response_embedding(response)\n","        x_r = self.dropout(x_r)\n","\n","        x_k = self.knowledge_embedding(knowledge)\n","        x_k = self.dropout(x_k)\n","\n","        x_h = self.history_embedding(history)\n","        x_h = self.dropout(x_h)\n","\n","        # Run the LSTM along the sentences of length sent_len.\n","        output_r, (hidden_r, cell_r) = self.response_lstm(x_r)\n","        output_k, (hidden_k, cell_k) = self.knowledge_lstm(x_k)\n","        output_h, (hidden_h, cell_h) = self.history_lstm(x_h)\n","\n","        # Concat the final forward (hidden[-2,:,:]) and backward (hidden[-1,:,:]) hidden layers and apply dropout\n","        hidden_r = torch.cat((hidden_r[-2,:,:], hidden_r[-1,:,:]), -1)\n","        hidden_k = torch.cat((hidden_k[-2,:,:], hidden_k[-1,:,:]), -1)\n","        hidden_h = torch.cat((hidden_h[-2,:,:], hidden_h[-1,:,:]), -1)\n","        hidden = torch.cat((hidden_r, hidden_k, hidden_h), -1)\n","        hidden = self.dropout(hidden)\n","\n","        return self.fc(hidden)"]},{"cell_type":"code","execution_count":109,"metadata":{"id":"26V7ArBSBIRX","executionInfo":{"status":"ok","timestamp":1683487627662,"user_tz":240,"elapsed":7,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}}},"outputs":[],"source":["from torch import nn\n","import transformers\n","\n","class Transformer(nn.Module):\n","    def __init__(self, output_dim, dropout):\n","\n","        super().__init__()\n","\n","        # Initialize Bert layer\n","        config = transformers.AutoConfig.from_pretrained(\"google/bert_uncased_L-4_H-256_A-4\")\n","        self.response_bert = transformers.AutoModel.from_pretrained(\"google/bert_uncased_L-4_H-256_A-4\")\n","        self.knowledge_bert = transformers.AutoModel.from_pretrained(\"google/bert_uncased_L-4_H-256_A-4\")\n","        self.history_bert = transformers.AutoModel.from_pretrained(\"google/bert_uncased_L-4_H-256_A-4\")\n","\n","        self.fc = nn.Linear(in_features=3*config.hidden_size,\n","                            out_features=output_dim)\n","\n","        # Initialize Dropout\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, response, response_lengths, knowledge, knowledge_lengths, history, history_lengths):\n","\n","        # swap LENGTH and BATCH_SIZE dimensions\n","        response = torch.reshape(response, (response.shape[1], response.shape[0]))\n","        knowledge = torch.reshape(knowledge, (knowledge.shape[1], knowledge.shape[0]))\n","        history = torch.reshape(history, (history.shape[1], history.shape[0]))\n","\n","        output_r = self.response_bert(response).pooler_output\n","        output_k = self.knowledge_bert(knowledge).pooler_output\n","        output_h = self.history_bert(history).pooler_output\n","\n","        hidden = torch.cat((output_r, output_k, output_h), -1)\n","        hidden = self.dropout(hidden)\n","\n","        return self.fc(hidden)"]},{"cell_type":"code","execution_count":110,"metadata":{"id":"QI-pxfr1QUqq","executionInfo":{"status":"ok","timestamp":1683487627663,"user_tz":240,"elapsed":8,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}}},"outputs":[],"source":["# use original LSTM\n","if MODEL_CONFIG == \"LSTM\":\n","    RESPONSE_INPUT_DIM = len(RESPONSE.vocab)\n","    KNOWLEDGE_INPUT_DIM = len(KNOWLEDGE.vocab)\n","    HISTORY_INPUT_DIM = len(HISTORY.vocab)\n","    EMBEDDING_DIM = 300\n","    HIDDEN_DIM = 256\n","    OUTPUT_DIM = 1\n","    N_LAYERS = 2\n","    BIDIRECTIONAL = True\n","    DROPOUT = 0.5\n","    RESPONSE_PAD_IDX = RESPONSE.vocab.stoi[RESPONSE.pad_token]\n","    KNOWLEDGE_PAD_IDX = KNOWLEDGE.vocab.stoi[KNOWLEDGE.pad_token]\n","    HISTORY_PAD_IDX = HISTORY.vocab.stoi[HISTORY.pad_token]\n","    \n","    model = LSTM(RESPONSE_INPUT_DIM,\n","                KNOWLEDGE_INPUT_DIM,\n","                HISTORY_INPUT_DIM,\n","                EMBEDDING_DIM,\n","                HIDDEN_DIM,\n","                OUTPUT_DIM,\n","                N_LAYERS,\n","                BIDIRECTIONAL,\n","                DROPOUT,\n","                RESPONSE_PAD_IDX,\n","                KNOWLEDGE_PAD_IDX,\n","                HISTORY_PAD_IDX)"]},{"cell_type":"code","execution_count":111,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RNT1jdMNAMgH","executionInfo":{"status":"ok","timestamp":1683487628617,"user_tz":240,"elapsed":962,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}},"outputId":"44caef79-7b99-4470-b0de-ec65fbe3f298"},"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at google/bert_uncased_L-4_H-256_A-4 were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of the model checkpoint at google/bert_uncased_L-4_H-256_A-4 were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of the model checkpoint at google/bert_uncased_L-4_H-256_A-4 were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}],"source":["if MODEL_CONFIG == \"BERT\":\n","    OUTPUT_DIM=1\n","    DROPOUT = 0.5\n","    model = Transformer(OUTPUT_DIM, DROPOUT) "]},{"cell_type":"code","execution_count":112,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IyXNhzOfQUqr","executionInfo":{"status":"ok","timestamp":1683487628618,"user_tz":240,"elapsed":7,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}},"outputId":"f19faef2-eb46-4f7b-97c7-f0cea28bc075"},"outputs":[{"output_type":"stream","name":"stdout","text":["The model has 33,512,449 trainable parameters\n"]}],"source":["def count_parameters(model):\n","    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n","\n","print(f'The model has {count_parameters(model):,} trainable parameters')"]},{"cell_type":"code","execution_count":113,"metadata":{"id":"M5QN73gYQUqr","executionInfo":{"status":"ok","timestamp":1683487628618,"user_tz":240,"elapsed":4,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}}},"outputs":[],"source":["# print(RESPONSE.vocab.vectors.shape)\n","# print(KNOWLEDGE.vocab.vectors.shape)\n","# print(HISTORY.vocab.vectors.shape)"]},{"cell_type":"code","execution_count":114,"metadata":{"id":"x36lpus-QUqr","executionInfo":{"status":"ok","timestamp":1683487628618,"user_tz":240,"elapsed":4,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}}},"outputs":[],"source":["if MODEL_CONFIG == \"LSTM\":\n","    model.response_embedding.weight.data.copy_(RESPONSE.vocab.vectors)\n","    model.knowledge_embedding.weight.data.copy_(KNOWLEDGE.vocab.vectors)\n","    model.history_embedding.weight.data.copy_(HISTORY.vocab.vectors)"]},{"cell_type":"code","execution_count":115,"metadata":{"id":"wxxPbBUIQUqr","executionInfo":{"status":"ok","timestamp":1683487629369,"user_tz":240,"elapsed":754,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}}},"outputs":[],"source":["if MODEL_CONFIG == \"LSTM\":\n","    UNK_IDX_R = RESPONSE.vocab.stoi[RESPONSE.unk_token]\n","    UNK_IDX_K = RESPONSE.vocab.stoi[KNOWLEDGE.unk_token]\n","    UNK_IDX_H = RESPONSE.vocab.stoi[HISTORY.unk_token]\n","\n","    model.response_embedding.weight.data[UNK_IDX_R] = torch.zeros(EMBEDDING_DIM)\n","    model.response_embedding.weight.data[RESPONSE_PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n","\n","    model.knowledge_embedding.weight.data[UNK_IDX_K] = torch.zeros(EMBEDDING_DIM)\n","    model.knowledge_embedding.weight.data[KNOWLEDGE_PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n","\n","    model.history_embedding.weight.data[UNK_IDX_H] = torch.zeros(EMBEDDING_DIM)\n","    model.history_embedding.weight.data[HISTORY_PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n","\n","    print(model.response_embedding.weight.data)\n","    print(model.knowledge_embedding.weight.data)\n","    print(model.history_embedding.weight.data)"]},{"cell_type":"code","execution_count":116,"metadata":{"id":"qbo5y26lQUqr","executionInfo":{"status":"ok","timestamp":1683487629369,"user_tz":240,"elapsed":4,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}}},"outputs":[],"source":["import torch.optim as optim\n","\n","optimizer = optim.Adam(model.parameters())"]},{"cell_type":"code","execution_count":117,"metadata":{"id":"p1jpbDlCQUqs","executionInfo":{"status":"ok","timestamp":1683487629369,"user_tz":240,"elapsed":4,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}}},"outputs":[],"source":["criterion = nn.BCEWithLogitsLoss()\n","\n","model = model.to(device)\n","criterion = criterion.to(device)"]},{"cell_type":"code","execution_count":118,"metadata":{"id":"EeefTt3RQUqs","executionInfo":{"status":"ok","timestamp":1683487629370,"user_tz":240,"elapsed":5,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}}},"outputs":[],"source":["from sklearn.metrics import f1_score\n","\n","\n","def binary_accuracy(preds, y):\n","    \"\"\"\n","    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n","    \"\"\"\n","    #round predictions to the closest integer\n","    rounded_preds = torch.round(torch.sigmoid(preds))\n","    correct = (rounded_preds == y).float() #convert into float for division \n","    acc = correct.sum() / len(correct)\n","    return acc\n","\n","\n","def binary_f1(preds, y):\n","    # print(preds)\n","    # print(y)\n","    rounded_preds = torch.round(torch.sigmoid(preds))\n","    # f1 = f1_score(rounded_preds.detach().cpu(), y.detach().cpu(), average=\"macro\")\n","    # f1 = f1_score(y.detach().cpu(), rounded_preds.detatch().cpu(), average=\"macro\")\n","    f1 = f1_score(y.cpu(), rounded_preds.cpu(), average=\"macro\")\n","\n","    return f1\n"]},{"cell_type":"code","execution_count":119,"metadata":{"id":"syBOhKqsQUqs","executionInfo":{"status":"ok","timestamp":1683487629370,"user_tz":240,"elapsed":4,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}}},"outputs":[],"source":["def train(model, iterator, optimizer, criterion):\n","\n","    epoch_loss = 0\n","    epoch_acc = 0\n","\n","    model.train()\n","\n","    for batch in iterator:\n","\n","        optimizer.zero_grad()\n","\n","        response, response_lengths = batch.r\n","        knowledge, knowledge_lengths = batch.k\n","        history, history_lengths = batch.h\n","\n","        predictions = model(response, response_lengths, knowledge, knowledge_lengths, history, history_lengths).squeeze(1)\n","\n","        loss = criterion(predictions, batch.l)\n","\n","        acc = binary_accuracy(predictions, batch.l)\n","\n","        loss.backward()\n","\n","        optimizer.step()\n","\n","        epoch_loss += loss.item()\n","        epoch_acc += acc.item()\n","\n","    return epoch_loss / len(iterator), epoch_acc / len(iterator)"]},{"cell_type":"code","execution_count":120,"metadata":{"id":"LU-Fvt9JQUqs","executionInfo":{"status":"ok","timestamp":1683487629370,"user_tz":240,"elapsed":4,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}}},"outputs":[],"source":["def evaluate(model, iterator, criterion):\n","\n","    epoch_loss = 0\n","    epoch_acc = 0\n","    epoch_f1 = 0\n","\n","    model.eval()\n","\n","    with torch.no_grad():\n","\n","        for batch in iterator:\n","            response, response_lengths = batch.r\n","            knowledge, knowledge_lengths = batch.k\n","            history, history_lengths = batch.h\n","\n","            predictions = model(response, response_lengths, knowledge, knowledge_lengths, history, history_lengths).squeeze(1)\n","\n","            loss = criterion(predictions, batch.l)\n","            acc = binary_accuracy(predictions, batch.l)\n","            f1 = binary_f1(predictions, batch.l)\n","\n","            epoch_loss += loss.item()\n","            epoch_acc += acc.item()\n","            epoch_f1 += f1.item()\n","\n","    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_f1 / len(iterator)"]},{"cell_type":"code","execution_count":121,"metadata":{"id":"lMpGhV9jQUqs","executionInfo":{"status":"ok","timestamp":1683487629370,"user_tz":240,"elapsed":4,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}}},"outputs":[],"source":["import time\n","\n","def epoch_time(start_time, end_time):\n","    elapsed_time = end_time - start_time\n","    elapsed_mins = int(elapsed_time / 60)\n","    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n","    return elapsed_mins, elapsed_secs"]},{"cell_type":"code","execution_count":122,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":485},"id":"1asXdkH-QUqs","executionInfo":{"status":"error","timestamp":1683488251784,"user_tz":240,"elapsed":622418,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}},"outputId":"ae236ac8-b0e4-42fc-b5de-eeff61aaa29b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 01 | Epoch Time: 3m 53s\n","\tTrain Loss: 0.711 | Train Acc: 55.76% |\n","\t Val. Loss: 0.673 |  Val. Acc: 60.00% | Val. F1: 0.436\n","Epoch: 02 | Epoch Time: 3m 53s\n","\tTrain Loss: 0.691 | Train Acc: 57.85% |\n","\t Val. Loss: 0.683 |  Val. Acc: 60.00% | Val. F1: 0.436\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-122-2a03ddfc2da6>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mvalid_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_f1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-119-67055ce3ea12>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, iterator, optimizer, criterion)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory_lengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse_lengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mknowledge\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mknowledge_lengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-109-592801fd6ee8>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, response, response_lengths, knowledge, knowledge_lengths, history, history_lengths)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0moutput_r\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse_bert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpooler_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0moutput_k\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mknowledge_bert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mknowledge\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpooler_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0moutput_h\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory_bert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpooler_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1018\u001b[0m             \u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m         )\n\u001b[0;32m-> 1020\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m   1021\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1022\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    608\u001b[0m                 )\n\u001b[1;32m    609\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    611\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    493\u001b[0m         \u001b[0;31m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0mself_attn_past_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpast_key_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpast_key_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 495\u001b[0;31m         self_attention_outputs = self.attention(\n\u001b[0m\u001b[1;32m    496\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[0moutput_attentions\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m     ) -> Tuple[torch.Tensor]:\n\u001b[0;32m--> 425\u001b[0;31m         self_outputs = self.self(\n\u001b[0m\u001b[1;32m    426\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0mvalue_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpast_key_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_layer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m             \u001b[0mkey_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose_for_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m             \u001b[0mvalue_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose_for_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mtranspose_for_scores\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtranspose_for_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0mnew_x_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_attention_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention_head_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_x_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["N_EPOCHS = 5\n","# path = F\"/content/gdrive/My Drive/bilstm_model.pt\"\n","path = PROJECT_ROOT + F\"/bert_model.pt\"\n","best_valid_loss = float('inf')\n","\n","for epoch in range(N_EPOCHS):\n","\n","    start_time = time.time()\n","\n","    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n","    valid_loss, valid_acc, valid_f1 = evaluate(model, valid_iterator, criterion)\n","\n","    end_time = time.time()\n","\n","    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n","\n","    if valid_loss < best_valid_loss:\n","        best_valid_loss = valid_loss\n","        torch.save(model.state_dict(), path)\n","\n","    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n","    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}% |')\n","    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}% | Val. F1: {valid_f1:.3f}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t5aHFK_HQUqs","executionInfo":{"status":"aborted","timestamp":1683488251785,"user_tz":240,"elapsed":8,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}}},"outputs":[],"source":["model.load_state_dict(torch.load(path, map_location=device))\n","\n","test_loss, test_acc, test_f1 = evaluate(model, test_iterator, criterion)\n","\n","print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}% | Test F1: {test_f1:.2f}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iOoouH7OUMHJ","executionInfo":{"status":"aborted","timestamp":1683488251785,"user_tz":240,"elapsed":7,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}}},"outputs":[],"source":["import spacy\n","nlp = spacy.load('en_core_web_sm')\n","\n","def predict_hallucination(model, knowledge, response):\n","    model.eval()\n","\n","    tokenized_r = [tok.text for tok in nlp.tokenizer(response)]\n","    indexed_r = [RESPONSE.vocab.stoi[t] for t in tokenized_r]\n","    length_r = [len(indexed_r)]\n","    tensor_r = torch.LongTensor(indexed_r).to(device)\n","    tensor_r = tensor_r.unsqueeze(1)\n","    length_tensor_r = torch.LongTensor(length_r)\n","\n","    tokenized_k = [tok.text for tok in nlp.tokenizer(knowledge)]\n","    indexed_k = [KNOWLEDGE.vocab.stoi[t] for t in tokenized_k]\n","    length_k = [len(indexed_k)]\n","    tensor_k = torch.LongTensor(indexed_k).to(device)\n","    tensor_k = tensor_k.unsqueeze(1)\n","    length_tensor_k = torch.LongTensor(length_k)\n","\n","    prediction = torch.sigmoid(model(tensor_r, length_tensor_r, tensor_k, length_tensor_k))\n","\n","    return prediction.item()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uCFZFBo1U3MO","executionInfo":{"status":"aborted","timestamp":1683488251786,"user_tz":240,"elapsed":8,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}}},"outputs":[],"source":["predict_hallucination(model, \"\", \"I love dogs\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f0LU-GstVIog","executionInfo":{"status":"aborted","timestamp":1683488251786,"user_tz":240,"elapsed":8,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}}},"outputs":[],"source":["predict_hallucination(model, \"\", \"Dogs are animals.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8HpFk6G2VLmU","executionInfo":{"status":"aborted","timestamp":1683488251786,"user_tz":240,"elapsed":7,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}}},"outputs":[],"source":["predict_hallucination(model, \"\", \"I was walking my dog last week.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_ZH_nqk6VQbP","executionInfo":{"status":"aborted","timestamp":1683488251786,"user_tz":240,"elapsed":7,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}}},"outputs":[],"source":["predict_hallucination(model, \"\", \"Dogs need to be walked daily.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hxV02zIwVYkH","executionInfo":{"status":"aborted","timestamp":1683488251787,"user_tz":240,"elapsed":8,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}}},"outputs":[],"source":["test_data[2].r"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nytN5bp8Vkpk","executionInfo":{"status":"aborted","timestamp":1683488251787,"user_tz":240,"elapsed":8,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}}},"outputs":[],"source":["predict_hallucination(model, \"\", \"Dylan's Candy Bar is a candy supplier.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vTT3ALVCVtm0","executionInfo":{"status":"aborted","timestamp":1683488251787,"user_tz":240,"elapsed":8,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}}},"outputs":[],"source":["predict_hallucination(model, \"\", \"Dylan's Candy Bar is my favorite great brand of candy.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-YUZpBhDFrXq","executionInfo":{"status":"aborted","timestamp":1683488251788,"user_tz":240,"elapsed":663787,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}}},"outputs":[],"source":["print(test_data[2].h)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K1h-8pHEF01y","executionInfo":{"status":"aborted","timestamp":1683488251788,"user_tz":240,"elapsed":663785,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xt89YaAt-b8G","executionInfo":{"status":"aborted","timestamp":1683488251788,"user_tz":240,"elapsed":663783,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}}},"outputs":[],"source":["# test BERT\n","test_tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n","test_model = BertModel.from_pretrained(\"bert-base-uncased\")\n","\n","inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1mJQOjuU_CuE","executionInfo":{"status":"aborted","timestamp":1683488251789,"user_tz":240,"elapsed":663782,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}}},"outputs":[],"source":["inputs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"17uFL4D__DZz","executionInfo":{"status":"aborted","timestamp":1683488251789,"user_tz":240,"elapsed":663780,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}}},"outputs":[],"source":["outputs = test_model(**inputs)\n","outputs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zFjqCu5U_F6T","executionInfo":{"status":"aborted","timestamp":1683488251789,"user_tz":240,"elapsed":663778,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}}},"outputs":[],"source":["outputs = model(inputs[\"input_ids\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wwXpdfbV_6E3","executionInfo":{"status":"aborted","timestamp":1683488251790,"user_tz":240,"elapsed":663777,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}}},"outputs":[],"source":["outputs[\"pooler_output\"][0].squeeze(-1)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rC1UOM3eA2y9","executionInfo":{"status":"aborted","timestamp":1683488252806,"user_tz":240,"elapsed":12,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}}},"outputs":[],"source":["outputs[\"pooler_output\"].squeeze(-1).size()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7x0cD6quA5c8","executionInfo":{"status":"aborted","timestamp":1683488252806,"user_tz":240,"elapsed":12,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}}},"outputs":[],"source":["loss, output = model(inputs[\"input_ids\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7bHCTQGaBhrO","executionInfo":{"status":"aborted","timestamp":1683488252806,"user_tz":240,"elapsed":11,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}}},"outputs":[],"source":["loss"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nGU3Kw1OBjRV","executionInfo":{"status":"aborted","timestamp":1683488252807,"user_tz":240,"elapsed":12,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}}},"outputs":[],"source":["output"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uFWACOufJ5EK","executionInfo":{"status":"aborted","timestamp":1683488252807,"user_tz":240,"elapsed":12,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}}},"outputs":[],"source":["import gc\n","model = None\n","torch.cuda.empty_cache()\n","gc.collect()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cDowqeO5J5al","executionInfo":{"status":"aborted","timestamp":1683488252808,"user_tz":240,"elapsed":13,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}}},"outputs":[],"source":["test_model(inputs.input_ids).pooler_output.size()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2VKEyTE2KzMf","executionInfo":{"status":"aborted","timestamp":1683488252808,"user_tz":240,"elapsed":13,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}}},"outputs":[],"source":["inputs.input_ids.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B7qH3XgvMSPg","executionInfo":{"status":"aborted","timestamp":1683488252809,"user_tz":240,"elapsed":14,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}}},"outputs":[],"source":["torch.flip(inputs.input_ids, []).shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C1xh0fsOMk7f","executionInfo":{"status":"aborted","timestamp":1683488252809,"user_tz":240,"elapsed":13,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}}},"outputs":[],"source":["torch.reshape(inputs.input_ids, (inputs.input_ids.shape[1], inputs.input_ids.shape[0])).shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wAL2MbIeNRxH","executionInfo":{"status":"aborted","timestamp":1683488252809,"user_tz":240,"elapsed":13,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}}},"outputs":[],"source":["torch.reshape(inputs.input_ids, (inputs.input_ids.shape[1], inputs.input_ids.shape[0]))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wH7hj3ClNY8a","executionInfo":{"status":"aborted","timestamp":1683488252810,"user_tz":240,"elapsed":14,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}}},"outputs":[],"source":["inputs.input_ids"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F6aDAU_ENcEd","executionInfo":{"status":"aborted","timestamp":1683488252810,"user_tz":240,"elapsed":14,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r8UuM5ZeNmsu","executionInfo":{"status":"aborted","timestamp":1683488252811,"user_tz":240,"elapsed":15,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}}},"outputs":[],"source":["\n","BertTokenizer.from_pretrained(\"google/bert_uncased_L-4_H-256_A-4\")\n","BertModel.from_pretrained(\"google/bert_uncased_L-4_H-256_A-4\")\n","# BertTokenizer.from_pretrained(\"bert-tiny\")\n","# BertModel.from_pretrained(\"bert-tiny\")"]},{"cell_type":"code","source":[],"metadata":{"id":"6IwW94s-XhHA","executionInfo":{"status":"aborted","timestamp":1683488252811,"user_tz":240,"elapsed":14,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}}},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10"},"widgets":{"application/vnd.jupyter.widget-state+json":{"5e3be46752e8494dbf51fa8d9695d807":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d99107d8fede42e6bef0d1bd1e794d36","IPY_MODEL_72db936feb8d4687a251baf1029862c3","IPY_MODEL_93bebb19189b4c74ae68ba80c1d8be7b"],"layout":"IPY_MODEL_ee27e19b5b1e4740920b68e9ab8b2777"}},"d99107d8fede42e6bef0d1bd1e794d36":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5f45693cbc05457abcfa1b401ae3479a","placeholder":"​","style":"IPY_MODEL_ec6539ce123640b880e40c7378281495","value":"100%"}},"72db936feb8d4687a251baf1029862c3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_70e33e52e55f455d8d77f3febb4a7a2a","max":7,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ee9b11c7675d41abb5d75fc6dbdb365b","value":7}},"93bebb19189b4c74ae68ba80c1d8be7b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_54648151c7cd4df698a3880d5aa8c207","placeholder":"​","style":"IPY_MODEL_02d6c9d1fff64a5fbea5d24f45426dcc","value":" 7/7 [00:00&lt;00:00, 160.24it/s]"}},"ee27e19b5b1e4740920b68e9ab8b2777":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5f45693cbc05457abcfa1b401ae3479a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ec6539ce123640b880e40c7378281495":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"70e33e52e55f455d8d77f3febb4a7a2a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ee9b11c7675d41abb5d75fc6dbdb365b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"54648151c7cd4df698a3880d5aa8c207":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"02d6c9d1fff64a5fbea5d24f45426dcc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}