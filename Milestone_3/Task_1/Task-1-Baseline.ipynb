{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JML6-VPnQUqh","executionInfo":{"status":"ok","timestamp":1682958879618,"user_tz":240,"elapsed":33422,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}},"outputId":"37191531-f57f-45ad-82b9-cdcc39348f80"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting torchtext==0.6.0\n","  Downloading torchtext-0.6.0-py3-none-any.whl (64 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.2/64.2 kB\u001b[0m \u001b[31m948.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (2.0.0+cu118)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (1.16.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (4.65.0)\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.98-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m41.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (1.22.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (2.27.1)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (1.26.15)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (2.0.12)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (2022.12.7)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (3.4)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (2.0.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (3.12.0)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (3.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (1.11.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (3.1.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (4.5.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->torchtext==0.6.0) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->torchtext==0.6.0) (16.0.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->torchtext==0.6.0) (2.1.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->torchtext==0.6.0) (1.3.0)\n","Installing collected packages: sentencepiece, torchtext\n","  Attempting uninstall: torchtext\n","    Found existing installation: torchtext 0.15.1\n","    Uninstalling torchtext-0.15.1:\n","      Successfully uninstalled torchtext-0.15.1\n","Successfully installed sentencepiece-0.1.98 torchtext-0.6.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting datasets\n","  Downloading datasets-2.12.0-py3-none-any.whl (474 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m474.6/474.6 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n","Collecting dill<0.3.7,>=0.3.0\n","  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting huggingface-hub<1.0.0,>=0.11.0\n","  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting responses<0.19\n","  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.22.4)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.65.0)\n","Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.4.0)\n","Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.27.1)\n","Collecting multiprocess\n","  Downloading multiprocess-0.70.14-py310-none-any.whl (134 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting xxhash\n","  Downloading xxhash-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.5/212.5 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting aiohttp\n","  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.0.12)\n","Collecting multidict<7.0,>=4.5\n","  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting aiosignal>=1.1.2\n","  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n","Collecting yarl<2.0,>=1.0\n","  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting frozenlist>=1.1.1\n","  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n","  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (4.5.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (3.12.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (1.26.15)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2022.7.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n","Installing collected packages: xxhash, multidict, frozenlist, dill, async-timeout, yarl, responses, multiprocess, huggingface-hub, aiosignal, aiohttp, datasets\n","Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 datasets-2.12.0 dill-0.3.6 frozenlist-1.3.3 huggingface-hub-0.14.1 multidict-6.0.4 multiprocess-0.70.14 responses-0.18.0 xxhash-3.2.0 yarl-1.9.2\n"]}],"source":["# ! pip install torchtext==0.10.1\n","! pip install torchtext==0.6.0\n","! pip install datasets"]},{"cell_type":"code","source":["from datasets import load_dataset\n","\n","import torch\n","from torchtext import data"],"metadata":{"id":"EDgQMtgJQfdJ","executionInfo":{"status":"ok","timestamp":1682958886041,"user_tz":240,"elapsed":6427,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N0sVqbn1Q8gv","executionInfo":{"status":"ok","timestamp":1682958905439,"user_tz":240,"elapsed":19401,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}},"outputId":"38ecb290-eca2-4695-de30-14176b81e64c"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"code","source":["MODEL_CONFIG = \"IMPROVEMENTS\"\n","print(\"Using MODEL_CONFIG\", MODEL_CONFIG)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6LhyMScREDpu","executionInfo":{"status":"ok","timestamp":1682959032751,"user_tz":240,"elapsed":529,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}},"outputId":"f59afe24-e649-44ba-8509-ebdd3933f5da"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["Using MODEL_CONFIG IMPROVEMENTS\n"]}]},{"cell_type":"code","source":["PROJECT_ROOT = F\"/content/gdrive/My Drive/nlp_project_task_1/\""],"metadata":{"id":"0zHpR9aKRA5F","executionInfo":{"status":"ok","timestamp":1682959033035,"user_tz":240,"elapsed":5,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","execution_count":30,"metadata":{"id":"ZHwitHvFQUqk","executionInfo":{"status":"ok","timestamp":1682959033036,"user_tz":240,"elapsed":5,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}}},"outputs":[],"source":["SEED = 42\n","MAX_VOCAB_SIZE = 25_000"]},{"cell_type":"code","execution_count":31,"metadata":{"id":"BS_qqwWkQUqk","executionInfo":{"status":"ok","timestamp":1682959033036,"user_tz":240,"elapsed":5,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}}},"outputs":[],"source":["torch.manual_seed(SEED)\n","torch.backends.cudnn.deterministic = True"]},{"cell_type":"code","execution_count":32,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ztb4YGEIQUql","executionInfo":{"status":"ok","timestamp":1682959033036,"user_tz":240,"elapsed":4,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}},"outputId":"11d78532-6d07-4958-e906-e6c25cb332d5"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda')"]},"metadata":{},"execution_count":32}],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","device"]},{"cell_type":"code","execution_count":33,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":84,"referenced_widgets":["d5df808e0c6345eda71d1a64e2a7c17b","fb56257c409b41eab35d97a71582510c","03585f4fcce24f38b7efd624247020ff","e6a75dd0ebaf43ad8d02c7a207826410","80f80782040244eeb5570ae805f56db8","3441a892bf0f420abdc8b66535886049","8fb617a1aa774b85829172d35afe7eaa","e0b1847c1e744a72aa2fb624f4228600","7a66fc49741542c49a0b3f50f0c1d5d2","2b3cb7d6bc144bba8628d3ead01956eb","b88a4680aeea4ae88fc16ebce8bb3301"]},"id":"REBQaOuFQUql","executionInfo":{"status":"ok","timestamp":1682959033949,"user_tz":240,"elapsed":916,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}},"outputId":"531d3c7b-3fb0-469b-ed6b-07989bf15a83"},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:datasets.builder:No config specified, defaulting to: faith_dial/plain_text\n","WARNING:datasets.builder:Found cached dataset faith_dial (/root/.cache/huggingface/datasets/McGill-NLP___faith_dial/plain_text/1.0.0/70568c8ab3bbc83b603bce58fa593ab27e7f0d0cde51034e1c2073ff3e14189a)\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/7 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d5df808e0c6345eda71d1a64e2a7c17b"}},"metadata":{}}],"source":["faithdial_dataset = load_dataset(\"McGill-NLP/FaithDial\")"]},{"cell_type":"code","execution_count":34,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"juF-GfX5QUqm","executionInfo":{"status":"ok","timestamp":1682959033950,"user_tz":240,"elapsed":8,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}},"outputId":"91028788-c510-4f09-cfe5-2966e0dbb3bb"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["dict_keys(['test', 'test_random_split', 'test_topic_split', 'train', 'validation', 'valid_random_split', 'valid_topic_split'])"]},"metadata":{},"execution_count":34}],"source":["faithdial_dataset.keys()"]},{"cell_type":"code","source":["faithdial_dataset[\"train\"][0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IzV6pQ3O3WLj","executionInfo":{"status":"ok","timestamp":1682959033950,"user_tz":240,"elapsed":6,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}},"outputId":"a09d8ae8-8160-491a-8648-e8bcd7632940"},"execution_count":35,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'dialog_idx': 0,\n"," 'response': 'Yeah, but once the access to the internet was a rare thing. do you remember?',\n"," 'original_response': \"No I could not! I couldn't imagine living when internet access was rare and very few people had it!\",\n"," 'history': ['Can you imagine the world without internet access?'],\n"," 'knowledge': 'Internet access was once rare, but has grown rapidly.',\n"," 'BEGIN': ['Hallucination'],\n"," 'VRM': ['Disclosure', 'Ack.']}"]},"metadata":{},"execution_count":35}]},{"cell_type":"code","execution_count":36,"metadata":{"id":"7aHU5_UXQUqm","executionInfo":{"status":"ok","timestamp":1682959033950,"user_tz":240,"elapsed":5,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}}},"outputs":[],"source":["def critic_preprocess(dataset):\n","    \"\"\"\n","    Data items transformed into (knowledge, response, is_hallucination)\n","    \"\"\"\n","    new_dataset = []\n","    for d in dataset:\n","        # original response\n","        if d[\"original_response\"] != None:\n","            new_dataset.append({\n","                \"knowledge\": d[\"knowledge\"],\n","                \"response\": d[\"original_response\"],\n","                \"hallucination\": \"yes\" if \"Hallucination\" in d[\"BEGIN\"] else \"no\",\n","                \"history\": \" \".join(d[\"history\"]),\n","                \"all\": \" \".join(d[\"history\"]) + \" <eos> \" + d[\"knowledge\"] + \" <eos> \" + d[\"original_response\"]\n","            })\n","\n","        # new responses always aren't hallucinations\n","        new_dataset.append({\"knowledge\": d[\"knowledge\"],\n","                            \"response\": d[\"response\"],\n","                            \"hallucination\": \"no\",\n","                            \"history\": \" \".join(d[\"history\"]),\n","                            \"all\": \" \".join(d[\"history\"]) + \" <eos> \" + d[\"knowledge\"] + \" <eos> \" + d[\"response\"]\n","        })\n","    return new_dataset"]},{"cell_type":"code","execution_count":37,"metadata":{"id":"NvX3XmUGQUqn","executionInfo":{"status":"ok","timestamp":1682959033950,"user_tz":240,"elapsed":4,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}}},"outputs":[],"source":["import json\n","\n","def dump_as_json(dataset, filename):\n","    \"\"\"\n","    Takes a list of dicts and dumps it as a json file that torchtext can parse.\n","    \"\"\"\n","    with open(filename, \"w\") as file:\n","        for d in dataset:\n","            file.write(json.dumps(d))\n","            file.write(\"\\n\")\n"]},{"cell_type":"code","execution_count":41,"metadata":{"id":"lprbGYNEQUqn","executionInfo":{"status":"ok","timestamp":1682959074121,"user_tz":240,"elapsed":3168,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}}},"outputs":[],"source":["KNOWLEDGE = data.Field(tokenize='spacy', tokenizer_language=\"en_core_web_sm\", include_lengths = True)\n","RESPONSE = data.Field(tokenize='spacy', tokenizer_language=\"en_core_web_sm\", include_lengths = True)\n","HISTORY = data.Field(tokenize='spacy', tokenizer_language=\"en_core_web_sm\", include_lengths = True)\n","LABEL = data.LabelField(dtype=torch.float)\n","\n","# ALL = data.Field(tokenize='spacy', tokenizer_language=\"en_core_web_sm\", include_lengths = True)"]},{"cell_type":"code","execution_count":42,"metadata":{"id":"h-8aVlf5QUqn","executionInfo":{"status":"ok","timestamp":1682959076844,"user_tz":240,"elapsed":2726,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}}},"outputs":[],"source":["dump_as_json(critic_preprocess(faithdial_dataset[\"test\"]), PROJECT_ROOT + \"data/faithdial_dataset_test.json\")\n","dump_as_json(critic_preprocess(faithdial_dataset[\"train\"]), PROJECT_ROOT + \"data/faithdial_dataset_train.json\")\n","dump_as_json(critic_preprocess(faithdial_dataset[\"validation\"]), PROJECT_ROOT + \"data/faithdial_dataset_validation.json\")"]},{"cell_type":"code","execution_count":43,"metadata":{"id":"V0aO873yQUqo","executionInfo":{"status":"ok","timestamp":1682959103348,"user_tz":240,"elapsed":26519,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}}},"outputs":[],"source":["fields = {\"knowledge\": (\"k\", KNOWLEDGE), \"response\": (\"r\", RESPONSE), \"hallucination\": (\"l\", LABEL), \"history\": (\"h\", HISTORY)}\n","# fields = {\"all\": (\"a\", ALL), \"hallucination\": (\"l\", LABEL)}\n","\n","dataset = data.TabularDataset.splits(path=PROJECT_ROOT + \"data\",\n","                                     train=\"faithdial_dataset_train.json\",\n","                                     validation=\"faithdial_dataset_validation.json\",\n","                                     test=\"faithdial_dataset_test.json\",\n","                                     format=\"json\",\n","                                     fields=fields)\n"]},{"cell_type":"code","execution_count":44,"metadata":{"id":"wpa0b_BcQUqo","executionInfo":{"status":"ok","timestamp":1682959103349,"user_tz":240,"elapsed":20,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}}},"outputs":[],"source":["train_data, valid_data, test_data = dataset"]},{"cell_type":"code","execution_count":45,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CB3RjeFzQUqo","executionInfo":{"status":"ok","timestamp":1682959103349,"user_tz":240,"elapsed":19,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}},"outputId":"fc012ecb-ad82-4b41-f5ff-49e9c39348ce"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torchtext.data.example.Example at 0x7fde8a089d20>"]},"metadata":{},"execution_count":45}],"source":["train_data[0]"]},{"cell_type":"code","execution_count":46,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CUIjXBl-QUqp","executionInfo":{"status":"ok","timestamp":1682959103349,"user_tz":240,"elapsed":17,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}},"outputId":"79602146-1c65-4651-aa3c-f3ed607f8c76"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'k': ['Internet',\n","  'access',\n","  'was',\n","  'once',\n","  'rare',\n","  ',',\n","  'but',\n","  'has',\n","  'grown',\n","  'rapidly',\n","  '.'],\n"," 'r': ['No',\n","  'I',\n","  'could',\n","  'not',\n","  '!',\n","  'I',\n","  'could',\n","  \"n't\",\n","  'imagine',\n","  'living',\n","  'when',\n","  'internet',\n","  'access',\n","  'was',\n","  'rare',\n","  'and',\n","  'very',\n","  'few',\n","  'people',\n","  'had',\n","  'it',\n","  '!'],\n"," 'l': 'yes',\n"," 'h': ['Can',\n","  'you',\n","  'imagine',\n","  'the',\n","  'world',\n","  'without',\n","  'internet',\n","  'access',\n","  '?']}"]},"metadata":{},"execution_count":46}],"source":["vars(train_data.examples[0])"]},{"cell_type":"code","execution_count":47,"metadata":{"id":"lD7OVfyOQUqp","executionInfo":{"status":"ok","timestamp":1682959105291,"user_tz":240,"elapsed":1956,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}}},"outputs":[],"source":["KNOWLEDGE.build_vocab(train_data,\n","                      max_size=MAX_VOCAB_SIZE,\n","                      vectors = \"fasttext.simple.300d\",\n","                      unk_init = torch.Tensor.normal_)\n","RESPONSE.build_vocab(train_data,\n","                     max_size=MAX_VOCAB_SIZE,\n","                     vectors = \"fasttext.simple.300d\",\n","                     unk_init = torch.Tensor.normal_)\n","HISTORY.build_vocab(train_data,\n","                    max_size=MAX_VOCAB_SIZE,\n","                    vectors = \"fasttext.simple.300d\",\n","                    unk_init = torch.Tensor.normal_)\n","LABEL.build_vocab(train_data)\n","\n","# ALL.build_vocab(train_data,\n","#                 specials=[\"<eos>\"],\n","#                 max_size=MAX_VOCAB_SIZE,\n","#                 vectors = \"fasttext.simple.300d\",\n","#                 unk_init = torch.Tensor.normal_)\n"]},{"cell_type":"code","execution_count":48,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zBEl747NQUqp","executionInfo":{"status":"ok","timestamp":1682959105291,"user_tz":240,"elapsed":11,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}},"outputId":"a051e5b2-e6a3-4ecb-8366-581047db4088"},"outputs":[{"output_type":"stream","name":"stdout","text":["Unique tokens in KNOWLEDGE vocabulary: 24539\n","Unique tokens in RESPONSE vocabulary: 25002\n","Unique tokens in HISTORY vocabulary: 22340\n","Unique tokens in LABEL vocabulary: 2\n"]}],"source":["print(f\"Unique tokens in KNOWLEDGE vocabulary: {len(KNOWLEDGE.vocab)}\")\n","print(f\"Unique tokens in RESPONSE vocabulary: {len(RESPONSE.vocab)}\")\n","print(f\"Unique tokens in HISTORY vocabulary: {len(HISTORY.vocab)}\")\n","print(f\"Unique tokens in LABEL vocabulary: {len(LABEL.vocab)}\")"]},{"cell_type":"code","execution_count":49,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oYD0okYXQUqp","executionInfo":{"status":"ok","timestamp":1682959105291,"user_tz":240,"elapsed":9,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}},"outputId":"4651c309-3d2a-4d66-c659-69ce00d62673"},"outputs":[{"output_type":"stream","name":"stdout","text":["[(',', 61720), ('the', 38383), ('.', 33816), ('and', 28891), ('of', 26828), ('a', 20285), ('in', 19499), ('is', 17156), (\"''\", 16411), ('to', 12365), ('or', 9842), ('as', 9598), (')', 8496), ('-', 8327), ('(', 8142), ('The', 7870), ('by', 6639), ('with', 5784), ('for', 5683), ('are', 5067)]\n","[('.', 32770), (',', 31530), ('the', 24162), ('I', 18471), ('a', 14945), ('and', 13738), ('of', 13482), ('is', 12016), ('in', 11802), ('that', 10738), ('to', 10728), ('you', 8747), ('it', 8115), ('?', 7405), ('know', 6604), ('are', 6421), ('!', 6137), (\"'s\", 6079), ('have', 5205), ('but', 4822)]\n","[('.', 127919), ('I', 114029), (',', 110960), ('the', 73662), ('?', 70486), ('a', 59059), ('you', 53372), ('to', 45803), ('of', 44987), ('that', 43462), ('is', 43001), ('know', 37626), ('and', 37304), ('it', 36219), ('in', 32770), ('do', 27194), ('!', 24244), ('have', 23839), (\"'s\", 23079), ('are', 20923)]\n","[('no', 20474), ('yes', 13507)]\n"]}],"source":["print(KNOWLEDGE.vocab.freqs.most_common(20))\n","print(RESPONSE.vocab.freqs.most_common(20))\n","print(HISTORY.vocab.freqs.most_common(20))\n","print(LABEL.vocab.freqs.most_common(20))"]},{"cell_type":"code","execution_count":50,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ulp3hp87QUqq","executionInfo":{"status":"ok","timestamp":1682959105292,"user_tz":240,"elapsed":7,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}},"outputId":"f3ceb932-253d-4496-bb40-a9ea600d6387"},"outputs":[{"output_type":"stream","name":"stdout","text":["['<unk>', '<pad>', ',', 'the', '.', 'and', 'of', 'a', 'in', 'is']\n","['<unk>', '<pad>', '.', ',', 'the', 'I', 'a', 'and', 'of', 'is']\n","['<unk>', '<pad>', '.', 'I', ',', 'the', '?', 'a', 'you', 'to']\n","['no', 'yes']\n"]}],"source":["print(KNOWLEDGE.vocab.itos[:10])\n","print(RESPONSE.vocab.itos[:10])\n","print(HISTORY.vocab.itos[:10])\n","print(LABEL.vocab.itos[:10])"]},{"cell_type":"code","execution_count":51,"metadata":{"id":"vTvVnXnvQUqq","executionInfo":{"status":"ok","timestamp":1682959105292,"user_tz":240,"elapsed":5,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}}},"outputs":[],"source":["BATCH_SIZE = 64\n","\n","train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n","    (train_data, valid_data, test_data),\n","    batch_size = BATCH_SIZE,\n","    sort_within_batch = True,\n","    sort_key = lambda x: x.r,\n","    device = device)"]},{"cell_type":"code","execution_count":52,"metadata":{"id":"4NPgijQBQUqq","executionInfo":{"status":"ok","timestamp":1682959105292,"user_tz":240,"elapsed":5,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}}},"outputs":[],"source":["from torch import nn\n","\n","class LSTM(nn.Module):\n","    def __init__(self, response_vocab_size, knowledge_vocab_size, history_vocab_size, embedding_dim, hidden_dim, output_dim, n_layers,\n","                 bidirectional, dropout, response_pad_idx, knowledge_pad_idx, history_pad_idx):\n","\n","        super().__init__()\n","\n","        # Initialize Embedding Layer\n","        self.response_embedding = nn.Embedding(num_embeddings=response_vocab_size,\n","                                               embedding_dim=embedding_dim,\n","                                               padding_idx=response_pad_idx)\n","\n","        self.knowledge_embedding = nn.Embedding(num_embeddings=knowledge_vocab_size,\n","                                                embedding_dim=embedding_dim,\n","                                                padding_idx=knowledge_pad_idx)\n","        \n","        self.history_embedding = nn.Embedding(num_embeddings=history_vocab_size,\n","                                              embedding_dim=embedding_dim,\n","                                              padding_idx=history_pad_idx)\n","\n","        # Initialize LSTM layer\n","        self.response_lstm = nn.LSTM(input_size=embedding_dim,\n","                                     hidden_size=hidden_dim,\n","                                     num_layers=n_layers,\n","                                     bidirectional=bidirectional)\n","\n","        self.knowledge_lstm = nn.LSTM(input_size=embedding_dim,\n","                                      hidden_size=hidden_dim,\n","                                      num_layers=n_layers,\n","                                      bidirectional=bidirectional)\n","        \n","        self.history_lstm = nn.LSTM(input_size=embedding_dim,\n","                                    hidden_size=hidden_dim,\n","                                    num_layers=n_layers,\n","                                    bidirectional=bidirectional)\n","\n","        # Initialize a fully connected layer with Linear transformation\n","        self.fc = nn.Linear(in_features=3*2*hidden_dim,\n","                            out_features=output_dim)\n","\n","        # Initialize Dropout\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, response, response_lengths, knowledge, knowledge_lengths, history, history_lengths):\n","        # Apply embedding layer that matches each word to its vector and apply dropout. Dim [sent_len, batch_size, emb_dim]\n","        x_r = self.response_embedding(response)\n","        x_r = self.dropout(x_r)\n","\n","        x_k = self.knowledge_embedding(knowledge)\n","        x_k = self.dropout(x_k)\n","\n","        x_h = self.history_embedding(history)\n","        x_h = self.dropout(x_h)\n","\n","        # Run the LSTM along the sentences of length sent_len.\n","        output_r, (hidden_r, cell_r) = self.response_lstm(x_r)\n","        output_k, (hidden_k, cell_k) = self.knowledge_lstm(x_k)\n","        output_h, (hidden_h, cell_h) = self.history_lstm(x_h)\n","\n","        # Concat the final forward (hidden[-2,:,:]) and backward (hidden[-1,:,:]) hidden layers and apply dropout\n","        hidden_r = torch.cat((hidden_r[-2,:,:], hidden_r[-1,:,:]), -1)\n","        hidden_k = torch.cat((hidden_k[-2,:,:], hidden_k[-1,:,:]), -1)\n","        hidden_h = torch.cat((hidden_h[-2,:,:], hidden_h[-1,:,:]), -1)\n","        hidden = torch.cat((hidden_r, hidden_k, hidden_h), -1)\n","        hidden = self.dropout(hidden)\n","\n","        return self.fc(hidden)"]},{"cell_type":"code","source":["# from torch import nn\n","\n","# class ConcatLSTM(nn.Module):\n","#     def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers,\n","#                  bidirectional, dropout, pad_idx):\n","\n","#         super().__init__()\n","\n","#         # Initialize Embedding Layer\n","#         self.embedding = nn.Embedding(num_embeddings=vocab_size,\n","#                                                embedding_dim=embedding_dim,\n","#                                                padding_idx=pad_idx)\n","\n","#         # Initialize LSTM layer\n","#         self.lstm = nn.LSTM(input_size=embedding_dim,\n","#                             hidden_size=hidden_dim,\n","#                             num_layers=n_layers,\n","#                             bidirectional=bidirectional)\n","\n","#         # Initialize a fully connected layer with Linear transformation\n","#         self.fc = nn.Linear(in_features=2*hidden_dim,\n","#                             out_features=output_dim)\n","\n","#         # Initialize Dropout\n","#         self.dropout = nn.Dropout(dropout)\n","\n","#     def forward(self, all, all_lengths):\n","#         # Apply embedding layer that matches each word to its vector and apply dropout. Dim [sent_len, batch_size, emb_dim]\n","#         x = self.embedding(all)\n","#         x = self.dropout(x)\n","\n","#         # Run the LSTM along the sentences of length sent_len.\n","#         output, (hidden, cell) = self.lstm(x)\n","\n","#         # Concat the final forward (hidden[-2,:,:]) and backward (hidden[-1,:,:]) hidden layers and apply dropout\n","#         hidden = torch.cat((hidden[-2,:,:], hidden[-1,:,:]), -1)\n","#         hidden = self.dropout(hidden)\n","\n","#         return self.fc(hidden)"],"metadata":{"id":"vk9Y962URy7X","executionInfo":{"status":"ok","timestamp":1682959105293,"user_tz":240,"elapsed":6,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}}},"execution_count":53,"outputs":[]},{"cell_type":"code","execution_count":54,"metadata":{"id":"QI-pxfr1QUqq","executionInfo":{"status":"ok","timestamp":1682959105684,"user_tz":240,"elapsed":396,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}}},"outputs":[],"source":["RESPONSE_INPUT_DIM = len(RESPONSE.vocab)\n","KNOWLEDGE_INPUT_DIM = len(KNOWLEDGE.vocab)\n","HISTORY_INPUT_DIM = len(HISTORY.vocab)\n","EMBEDDING_DIM = 300\n","HIDDEN_DIM = 256\n","OUTPUT_DIM = 1\n","N_LAYERS = 2\n","BIDIRECTIONAL = True\n","DROPOUT = 0.5\n","RESPONSE_PAD_IDX = RESPONSE.vocab.stoi[RESPONSE.pad_token]\n","KNOWLEDGE_PAD_IDX = KNOWLEDGE.vocab.stoi[KNOWLEDGE.pad_token]\n","HISTORY_PAD_IDX = HISTORY.vocab.stoi[HISTORY.pad_token]\n","\n","\n","model = LSTM(RESPONSE_INPUT_DIM,\n","             KNOWLEDGE_INPUT_DIM,\n","             HISTORY_INPUT_DIM,\n","             EMBEDDING_DIM,\n","             HIDDEN_DIM,\n","             OUTPUT_DIM,\n","             N_LAYERS,\n","             BIDIRECTIONAL,\n","             DROPOUT,\n","             RESPONSE_PAD_IDX,\n","             KNOWLEDGE_PAD_IDX,\n","             HISTORY_PAD_IDX)"]},{"cell_type":"code","execution_count":55,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IyXNhzOfQUqr","executionInfo":{"status":"ok","timestamp":1682959105957,"user_tz":240,"elapsed":275,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}},"outputId":"144849b6-2d3f-4381-981e-79a7c1441f10"},"outputs":[{"output_type":"stream","name":"stdout","text":["The model has 29,725,069 trainable parameters\n"]}],"source":["def count_parameters(model):\n","    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n","\n","print(f'The model has {count_parameters(model):,} trainable parameters')"]},{"cell_type":"code","execution_count":56,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M5QN73gYQUqr","executionInfo":{"status":"ok","timestamp":1682959105958,"user_tz":240,"elapsed":11,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}},"outputId":"3233e5bd-4ff6-4dbb-9c59-b3e6790947f9"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([25002, 300])\n","torch.Size([24539, 300])\n","torch.Size([22340, 300])\n"]}],"source":["print(RESPONSE.vocab.vectors.shape)\n","print(KNOWLEDGE.vocab.vectors.shape)\n","print(HISTORY.vocab.vectors.shape)"]},{"cell_type":"code","execution_count":57,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x36lpus-QUqr","executionInfo":{"status":"ok","timestamp":1682959105958,"user_tz":240,"elapsed":9,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}},"outputId":"37e0f517-7358-4576-c583-30bbdb41caf6"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 1.6184,  0.0979,  1.1739,  ..., -2.3628,  0.8702, -1.4477],\n","        [ 0.1974, -0.0730, -0.4950,  ..., -1.1911,  0.0557,  1.7617],\n","        [ 0.0569, -0.0520,  0.2733,  ..., -0.0695, -0.1606, -0.0989],\n","        ...,\n","        [-0.3497,  0.0489, -0.1498,  ..., -0.0549,  0.0259, -0.2769],\n","        [ 0.5550,  0.1573, -0.2594,  ...,  0.0232,  0.1095, -0.0642],\n","        [ 0.0820,  0.3241, -0.4957,  ...,  0.1171,  0.1461, -0.3180]])"]},"metadata":{},"execution_count":57}],"source":["model.response_embedding.weight.data.copy_(RESPONSE.vocab.vectors)\n","model.knowledge_embedding.weight.data.copy_(KNOWLEDGE.vocab.vectors)\n","model.history_embedding.weight.data.copy_(HISTORY.vocab.vectors)"]},{"cell_type":"code","execution_count":58,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wxxPbBUIQUqr","executionInfo":{"status":"ok","timestamp":1682959105958,"user_tz":240,"elapsed":7,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}},"outputId":"08dd6253-c0e4-4566-fa46-e15e551639dd"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n","        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n","        [ 0.0569, -0.0520,  0.2733,  ..., -0.0695, -0.1606, -0.0989],\n","        ...,\n","        [ 0.7385,  0.2614,  0.3067,  ..., -0.1981, -0.2725, -0.0737],\n","        [ 0.3933, -0.1404, -0.0947,  ...,  0.0495,  0.0273, -0.0339],\n","        [ 0.1373, -0.1097,  0.1443,  ...,  0.0776, -0.1282, -0.0274]])\n","tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n","          0.0000e+00,  0.0000e+00],\n","        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n","          0.0000e+00,  0.0000e+00],\n","        [ 2.0132e-01,  1.0376e-02,  1.6235e-01,  ..., -9.3056e-02,\n","         -1.4075e-01, -1.3264e-01],\n","        ...,\n","        [ 1.0595e-01,  2.1516e-01, -1.8881e-01,  ...,  2.2973e-01,\n","         -2.7972e-01, -1.1228e+00],\n","        [-1.8776e-03, -7.1971e-01,  2.5737e+00,  ...,  5.9717e-01,\n","         -1.1907e+00, -1.2164e+00],\n","        [-1.9317e+00,  2.0529e-02, -1.3734e+00,  ...,  5.9376e-02,\n","          5.0052e-01,  2.7803e-01]])\n","tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n","        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n","        [ 0.0569, -0.0520,  0.2733,  ..., -0.0695, -0.1606, -0.0989],\n","        ...,\n","        [-0.3497,  0.0489, -0.1498,  ..., -0.0549,  0.0259, -0.2769],\n","        [ 0.5550,  0.1573, -0.2594,  ...,  0.0232,  0.1095, -0.0642],\n","        [ 0.0820,  0.3241, -0.4957,  ...,  0.1171,  0.1461, -0.3180]])\n"]}],"source":["UNK_IDX_R = RESPONSE.vocab.stoi[RESPONSE.unk_token]\n","UNK_IDX_K = RESPONSE.vocab.stoi[KNOWLEDGE.unk_token]\n","UNK_IDX_H = RESPONSE.vocab.stoi[HISTORY.unk_token]\n","\n","model.response_embedding.weight.data[UNK_IDX_R] = torch.zeros(EMBEDDING_DIM)\n","model.response_embedding.weight.data[RESPONSE_PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n","\n","model.knowledge_embedding.weight.data[UNK_IDX_K] = torch.zeros(EMBEDDING_DIM)\n","model.knowledge_embedding.weight.data[KNOWLEDGE_PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n","\n","model.history_embedding.weight.data[UNK_IDX_H] = torch.zeros(EMBEDDING_DIM)\n","model.history_embedding.weight.data[HISTORY_PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n","\n","print(model.response_embedding.weight.data)\n","print(model.knowledge_embedding.weight.data)\n","print(model.history_embedding.weight.data)"]},{"cell_type":"code","execution_count":59,"metadata":{"id":"qbo5y26lQUqr","executionInfo":{"status":"ok","timestamp":1682959105959,"user_tz":240,"elapsed":5,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}}},"outputs":[],"source":["import torch.optim as optim\n","\n","optimizer = optim.Adam(model.parameters())"]},{"cell_type":"code","execution_count":60,"metadata":{"id":"p1jpbDlCQUqs","executionInfo":{"status":"ok","timestamp":1682959109026,"user_tz":240,"elapsed":3071,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}}},"outputs":[],"source":["criterion = nn.BCEWithLogitsLoss()\n","\n","model = model.to(device)\n","criterion = criterion.to(device)"]},{"cell_type":"code","execution_count":61,"metadata":{"id":"EeefTt3RQUqs","executionInfo":{"status":"ok","timestamp":1682959109891,"user_tz":240,"elapsed":867,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}}},"outputs":[],"source":["from sklearn.metrics import f1_score\n","\n","\n","def binary_accuracy(preds, y):\n","    \"\"\"\n","    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n","    \"\"\"\n","    #round predictions to the closest integer\n","    rounded_preds = torch.round(torch.sigmoid(preds))\n","    correct = (rounded_preds == y).float() #convert into float for division \n","    acc = correct.sum() / len(correct)\n","    return acc\n","\n","\n","def binary_f1(preds, y):\n","    rounded_preds = torch.round(torch.sigmoid(preds))\n","    f1 = f1_score(y.cpu(), rounded_preds.cpu(), average=\"macro\")\n","\n","    return f1\n"]},{"cell_type":"code","execution_count":62,"metadata":{"id":"syBOhKqsQUqs","executionInfo":{"status":"ok","timestamp":1682959109891,"user_tz":240,"elapsed":4,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}}},"outputs":[],"source":["def train(model, iterator, optimizer, criterion):\n","\n","    epoch_loss = 0\n","    epoch_acc = 0\n","\n","    model.train()\n","\n","    for batch in iterator:\n","\n","        optimizer.zero_grad()\n","\n","        response, response_lengths = batch.r\n","        knowledge, knowledge_lengths = batch.k\n","        history, history_lengths = batch.h\n","\n","        predictions = model(response, response_lengths, knowledge, knowledge_lengths, history, history_lengths).squeeze(1)\n","\n","        loss = criterion(predictions, batch.l)\n","        acc = binary_accuracy(predictions, batch.l)\n","\n","        loss.backward()\n","        optimizer.step()\n","\n","        epoch_loss += loss.item()\n","        epoch_acc += acc.item()\n","\n","    return epoch_loss / len(iterator), epoch_acc / len(iterator)"]},{"cell_type":"code","execution_count":63,"metadata":{"id":"LU-Fvt9JQUqs","executionInfo":{"status":"ok","timestamp":1682959109892,"user_tz":240,"elapsed":4,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}}},"outputs":[],"source":["def evaluate(model, iterator, criterion):\n","\n","    epoch_loss = 0\n","    epoch_acc = 0\n","    epoch_f1 = 0\n","\n","    model.eval()\n","\n","    with torch.no_grad():\n","\n","        for batch in iterator:\n","            response, response_lengths = batch.r\n","            knowledge, knowledge_lengths = batch.k\n","            history, history_lengths = batch.h\n","\n","            predictions = model(response, response_lengths, knowledge, knowledge_lengths, history, history_lengths).squeeze(1)\n","\n","            loss = criterion(predictions, batch.l)\n","            acc = binary_accuracy(predictions, batch.l)\n","            f1 = binary_f1(predictions, batch.l)\n","\n","            epoch_loss += loss.item()\n","            epoch_acc += acc.item()\n","            epoch_f1 += f1.item()\n","\n","    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_f1 / len(iterator)"]},{"cell_type":"code","execution_count":64,"metadata":{"id":"lMpGhV9jQUqs","executionInfo":{"status":"ok","timestamp":1682959109892,"user_tz":240,"elapsed":3,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}}},"outputs":[],"source":["import time\n","\n","def epoch_time(start_time, end_time):\n","    elapsed_time = end_time - start_time\n","    elapsed_mins = int(elapsed_time / 60)\n","    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n","    return elapsed_mins, elapsed_secs"]},{"cell_type":"code","execution_count":65,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1asXdkH-QUqs","executionInfo":{"status":"ok","timestamp":1682959567573,"user_tz":240,"elapsed":457684,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}},"outputId":"dd256456-ab04-44ad-eab4-dc3f2740f949"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 01 | Epoch Time: 1m 29s\n","\tTrain Loss: 0.504 | Train Acc: 74.72% |\n","\t Val. Loss: 0.398 |  Val. Acc: 82.29% | Val. F1: 0.777\n","Epoch: 02 | Epoch Time: 1m 30s\n","\tTrain Loss: 0.367 | Train Acc: 83.82% |\n","\t Val. Loss: 0.375 |  Val. Acc: 83.20% | Val. F1: 0.790\n","Epoch: 03 | Epoch Time: 1m 31s\n","\tTrain Loss: 0.307 | Train Acc: 86.93% |\n","\t Val. Loss: 0.372 |  Val. Acc: 84.10% | Val. F1: 0.801\n","Epoch: 04 | Epoch Time: 1m 31s\n","\tTrain Loss: 0.264 | Train Acc: 89.08% |\n","\t Val. Loss: 0.354 |  Val. Acc: 84.14% | Val. F1: 0.805\n","Epoch: 05 | Epoch Time: 1m 32s\n","\tTrain Loss: 0.226 | Train Acc: 90.70% |\n","\t Val. Loss: 0.380 |  Val. Acc: 83.67% | Val. F1: 0.801\n"]}],"source":["N_EPOCHS = 5\n","path = PROJECT_ROOT + \"/\" + MODEL_CONFIG + \"_model.pt\"\n","best_valid_loss = float('inf')\n","\n","for epoch in range(N_EPOCHS):\n","\n","    start_time = time.time()\n","\n","    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n","    valid_loss, valid_acc, valid_f1 = evaluate(model, valid_iterator, criterion)\n","\n","    end_time = time.time()\n","\n","    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n","\n","    if valid_loss < best_valid_loss:\n","        best_valid_loss = valid_loss\n","        torch.save(model.state_dict(), path)\n","\n","    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n","    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}% |')\n","    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}% | Val. F1: {valid_f1:.3f}')"]},{"cell_type":"code","execution_count":66,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t5aHFK_HQUqs","executionInfo":{"status":"ok","timestamp":1682959573690,"user_tz":240,"elapsed":6120,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}},"outputId":"02c0c6f1-cc35-412c-82a2-5b9dabf98ec1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Test Loss: 0.350 | Test Acc: 84.90% | Test F1: 0.81\n"]}],"source":["model.load_state_dict(torch.load(path, map_location=device))\n","\n","test_loss, test_acc, test_f1 = evaluate(model, test_iterator, criterion)\n","\n","print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}% | Test F1: {test_f1:.2f}')"]},{"cell_type":"code","source":["import spacy\n","nlp = spacy.load('en_core_web_sm')\n","\n","def predict_hallucination(model, knowledge, response):\n","    model.eval()\n","\n","    tokenized_r = [tok.text for tok in nlp.tokenizer(response)]\n","    indexed_r = [RESPONSE.vocab.stoi[t] for t in tokenized_r]\n","    length_r = [len(indexed_r)]\n","    tensor_r = torch.LongTensor(indexed_r).to(device)\n","    tensor_r = tensor_r.unsqueeze(1)\n","    length_tensor_r = torch.LongTensor(length_r)\n","\n","    tokenized_k = [tok.text for tok in nlp.tokenizer(knowledge)]\n","    indexed_k = [KNOWLEDGE.vocab.stoi[t] for t in tokenized_k]\n","    length_k = [len(indexed_k)]\n","    tensor_k = torch.LongTensor(indexed_k).to(device)\n","    tensor_k = tensor_k.unsqueeze(1)\n","    length_tensor_k = torch.LongTensor(length_k)\n","\n","    prediction = torch.sigmoid(model(tensor_r, length_tensor_r, tensor_k, length_tensor_k))\n","\n","    return prediction.item()\n"],"metadata":{"id":"iOoouH7OUMHJ","executionInfo":{"status":"ok","timestamp":1682959574733,"user_tz":240,"elapsed":1057,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}}},"execution_count":67,"outputs":[]},{"cell_type":"code","source":["predict_hallucination(model, \"\", \"I love dogs\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":311},"id":"uCFZFBo1U3MO","executionInfo":{"status":"error","timestamp":1682959574733,"user_tz":240,"elapsed":12,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}},"outputId":"87e34cec-d7f0-4f1b-ea79-daf07ca42bb1"},"execution_count":68,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-68-24053f06acd2>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredict_hallucination\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"I love dogs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-67-d7b7bc3a242a>\u001b[0m in \u001b[0;36mpredict_hallucination\u001b[0;34m(model, knowledge, response)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mlength_tensor_k\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlength_k\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_r\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength_tensor_r\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength_tensor_k\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: LSTM.forward() missing 2 required positional arguments: 'history' and 'history_lengths'"]}]},{"cell_type":"code","source":["predict_hallucination(model, \"\", \"Dogs are animals.\")"],"metadata":{"id":"f0LU-GstVIog","executionInfo":{"status":"aborted","timestamp":1682959574734,"user_tz":240,"elapsed":11,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["predict_hallucination(model, \"\", \"I was walking my dog last week.\")"],"metadata":{"id":"8HpFk6G2VLmU","executionInfo":{"status":"aborted","timestamp":1682959574734,"user_tz":240,"elapsed":10,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["predict_hallucination(model, \"\", \"Dogs need to be walked daily.\")"],"metadata":{"id":"_ZH_nqk6VQbP","executionInfo":{"status":"aborted","timestamp":1682959574734,"user_tz":240,"elapsed":10,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_data[2].r"],"metadata":{"id":"hxV02zIwVYkH","executionInfo":{"status":"aborted","timestamp":1682959574735,"user_tz":240,"elapsed":11,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["predict_hallucination(model, \"\", \"Dylan's Candy Bar is a candy supplier.\")"],"metadata":{"id":"nytN5bp8Vkpk","executionInfo":{"status":"aborted","timestamp":1682959574735,"user_tz":240,"elapsed":10,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["predict_hallucination(model, \"\", \"Dylan's Candy Bar is my favorite great brand of candy.\")"],"metadata":{"id":"vTT3ALVCVtm0","executionInfo":{"status":"aborted","timestamp":1682959574735,"user_tz":240,"elapsed":10,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(test_data[2].h)"],"metadata":{"id":"-YUZpBhDFrXq","executionInfo":{"status":"aborted","timestamp":1682959574736,"user_tz":240,"elapsed":11,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"K1h-8pHEF01y","executionInfo":{"status":"aborted","timestamp":1682959574736,"user_tz":240,"elapsed":11,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}}},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10"},"orig_nbformat":4,"colab":{"provenance":[]},"accelerator":"GPU","gpuClass":"standard","widgets":{"application/vnd.jupyter.widget-state+json":{"d5df808e0c6345eda71d1a64e2a7c17b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fb56257c409b41eab35d97a71582510c","IPY_MODEL_03585f4fcce24f38b7efd624247020ff","IPY_MODEL_e6a75dd0ebaf43ad8d02c7a207826410"],"layout":"IPY_MODEL_80f80782040244eeb5570ae805f56db8"}},"fb56257c409b41eab35d97a71582510c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3441a892bf0f420abdc8b66535886049","placeholder":"​","style":"IPY_MODEL_8fb617a1aa774b85829172d35afe7eaa","value":"100%"}},"03585f4fcce24f38b7efd624247020ff":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e0b1847c1e744a72aa2fb624f4228600","max":7,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7a66fc49741542c49a0b3f50f0c1d5d2","value":7}},"e6a75dd0ebaf43ad8d02c7a207826410":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2b3cb7d6bc144bba8628d3ead01956eb","placeholder":"​","style":"IPY_MODEL_b88a4680aeea4ae88fc16ebce8bb3301","value":" 7/7 [00:00&lt;00:00, 154.42it/s]"}},"80f80782040244eeb5570ae805f56db8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3441a892bf0f420abdc8b66535886049":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8fb617a1aa774b85829172d35afe7eaa":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e0b1847c1e744a72aa2fb624f4228600":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7a66fc49741542c49a0b3f50f0c1d5d2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2b3cb7d6bc144bba8628d3ead01956eb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b88a4680aeea4ae88fc16ebce8bb3301":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}