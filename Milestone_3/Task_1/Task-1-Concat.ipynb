{"cells":[{"cell_type":"code","execution_count":125,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":346},"id":"JML6-VPnQUqh","executionInfo":{"status":"error","timestamp":1682710871110,"user_tz":240,"elapsed":217,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}},"outputId":"525fc139-efcb-4af9-9ec2-90f2684c22c5"},"outputs":[{"output_type":"error","ename":"NotImplementedError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-125-5ec559f0d8f2>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# ! pip install torchtext==0.10.1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' pip install torchtext==0.6.0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' pip install datasets'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_shell.py\u001b[0m in \u001b[0;36msystem\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     97\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'also_return_output'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_system_commands\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_system_compat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint:disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpip_warn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_system_compat\u001b[0;34m(shell, cmd, also_return_output)\u001b[0m\n\u001b[1;32m    451\u001b[0m   \u001b[0;31m# is expected to call this function, thus adding one level of nesting to the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m   \u001b[0;31m# stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 453\u001b[0;31m   result = _run_command(\n\u001b[0m\u001b[1;32m    454\u001b[0m       \u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclear_streamed_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m   )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_run_command\u001b[0;34m(cmd, clear_streamed_output)\u001b[0m\n\u001b[1;32m    165\u001b[0m   \u001b[0mlocale_encoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlocale\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpreferredencoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mlocale_encoding\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0m_ENCODING\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m     raise NotImplementedError(\n\u001b[0m\u001b[1;32m    168\u001b[0m         \u001b[0;34m'A UTF-8 locale is required. Got {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocale_encoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     )\n","\u001b[0;31mNotImplementedError\u001b[0m: A UTF-8 locale is required. Got ANSI_X3.4-1968"]}],"source":["# ! pip install torchtext==0.10.1\n","! pip install torchtext==0.6.0\n","! pip install datasets"]},{"cell_type":"code","source":["from datasets import load_dataset\n","\n","import torch\n","from torchtext import data"],"metadata":{"id":"EDgQMtgJQfdJ","executionInfo":{"status":"ok","timestamp":1682710872323,"user_tz":240,"elapsed":3,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}}},"execution_count":126,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N0sVqbn1Q8gv","executionInfo":{"status":"ok","timestamp":1682710873593,"user_tz":240,"elapsed":1273,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}},"outputId":"b19e68da-f0ec-445c-fafb-89ce0278710d"},"execution_count":127,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["MODEL_CONFIG = \"CONCAT\"\n","print(\"Using MODEL_CONFIG\", MODEL_CONFIG)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6LhyMScREDpu","executionInfo":{"status":"ok","timestamp":1682710873594,"user_tz":240,"elapsed":8,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}},"outputId":"93fe530e-9323-44a0-ec26-19c002662cc3"},"execution_count":128,"outputs":[{"output_type":"stream","name":"stdout","text":["Using MODEL_CONFIG CONCAT\n"]}]},{"cell_type":"code","source":["PROJECT_ROOT = F\"/content/gdrive/My Drive/nlp_project_task_1/\""],"metadata":{"id":"0zHpR9aKRA5F","executionInfo":{"status":"ok","timestamp":1682710873594,"user_tz":240,"elapsed":6,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}}},"execution_count":129,"outputs":[]},{"cell_type":"code","execution_count":130,"metadata":{"id":"ZHwitHvFQUqk","executionInfo":{"status":"ok","timestamp":1682710873594,"user_tz":240,"elapsed":6,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}}},"outputs":[],"source":["SEED = 42\n","MAX_VOCAB_SIZE = 25_000"]},{"cell_type":"code","execution_count":131,"metadata":{"id":"BS_qqwWkQUqk","executionInfo":{"status":"ok","timestamp":1682710873594,"user_tz":240,"elapsed":5,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}}},"outputs":[],"source":["torch.manual_seed(SEED)\n","torch.backends.cudnn.deterministic = True"]},{"cell_type":"code","execution_count":132,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ztb4YGEIQUql","executionInfo":{"status":"ok","timestamp":1682710873595,"user_tz":240,"elapsed":6,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}},"outputId":"57f16de0-4021-4088-ea9a-a851415b78d3"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda')"]},"metadata":{},"execution_count":132}],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","device"]},{"cell_type":"code","execution_count":133,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":84,"referenced_widgets":["21513f7ecb124c8a9fa849942f72da4f","75231895b8ac4e1daf8b291508b0d936","39a6868d918a4be6b7817202184acdad","37946cf408b74026b3bdcbceee69b2f4","668abf4d18f34a1a9bddda476aa9ea7a","6d9fa821e01548b2bbce684f5fb974cc","c6de4b2df26e45469bd5ffd7fab4bd43","94eccd60a653411c8f467451f0b73ff5","a4600c9a907b4a759cef16e3ba844f4f","1a9dd98bfc2c48a6b51197c335c4d7de","3c788343e3fb4681902e9eefa6473ae2"]},"id":"REBQaOuFQUql","executionInfo":{"status":"ok","timestamp":1682710876100,"user_tz":240,"elapsed":2509,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}},"outputId":"7e991066-d0bd-4b70-a4a9-a93c38906726"},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:datasets.builder:No config specified, defaulting to: faith_dial/plain_text\n","WARNING:datasets.builder:Found cached dataset faith_dial (/root/.cache/huggingface/datasets/McGill-NLP___faith_dial/plain_text/1.0.0/70568c8ab3bbc83b603bce58fa593ab27e7f0d0cde51034e1c2073ff3e14189a)\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/7 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"21513f7ecb124c8a9fa849942f72da4f"}},"metadata":{}}],"source":["faithdial_dataset = load_dataset(\"McGill-NLP/FaithDial\")"]},{"cell_type":"code","execution_count":134,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"juF-GfX5QUqm","executionInfo":{"status":"ok","timestamp":1682710876101,"user_tz":240,"elapsed":9,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}},"outputId":"4c4385d4-53fb-47d2-fd59-ca140811a4eb"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["dict_keys(['test', 'test_random_split', 'test_topic_split', 'train', 'validation', 'valid_random_split', 'valid_topic_split'])"]},"metadata":{},"execution_count":134}],"source":["faithdial_dataset.keys()"]},{"cell_type":"code","source":["faithdial_dataset[\"train\"][0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IzV6pQ3O3WLj","executionInfo":{"status":"ok","timestamp":1682710876101,"user_tz":240,"elapsed":7,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}},"outputId":"841c28cd-c563-40df-818d-e24cee88b4cc"},"execution_count":135,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'dialog_idx': 0,\n"," 'response': 'Yeah, but once the access to the internet was a rare thing. do you remember?',\n"," 'original_response': \"No I could not! I couldn't imagine living when internet access was rare and very few people had it!\",\n"," 'history': ['Can you imagine the world without internet access?'],\n"," 'knowledge': 'Internet access was once rare, but has grown rapidly.',\n"," 'BEGIN': ['Hallucination'],\n"," 'VRM': ['Disclosure', 'Ack.']}"]},"metadata":{},"execution_count":135}]},{"cell_type":"code","execution_count":136,"metadata":{"id":"7aHU5_UXQUqm","executionInfo":{"status":"ok","timestamp":1682710876101,"user_tz":240,"elapsed":5,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}}},"outputs":[],"source":["def critic_preprocess(dataset):\n","    \"\"\"\n","    Data items transformed into (knowledge, response, is_hallucination)\n","    \"\"\"\n","    new_dataset = []\n","    for d in dataset:\n","        # original response\n","        if d[\"original_response\"] != None:\n","            new_dataset.append({\n","                \"knowledge\": d[\"knowledge\"],\n","                \"response\": d[\"original_response\"],\n","                \"hallucination\": \"yes\" if \"Hallucination\" in d[\"BEGIN\"] else \"no\",\n","                \"history\": \" \".join(d[\"history\"]),\n","                \"all\": \" \".join(d[\"history\"]) + \" <eos> \" + d[\"knowledge\"] + \" <eos> \" + d[\"original_response\"]\n","            })\n","\n","        # new responses always aren't hallucinations\n","        new_dataset.append({\"knowledge\": d[\"knowledge\"],\n","                            \"response\": d[\"response\"],\n","                            \"hallucination\": \"no\",\n","                            \"history\": \" \".join(d[\"history\"]),\n","                            \"all\": \" \".join(d[\"history\"]) + \" <eos> \" + d[\"knowledge\"] + \" <eos> \" + d[\"response\"]\n","        })\n","    return new_dataset"]},{"cell_type":"code","execution_count":137,"metadata":{"id":"NvX3XmUGQUqn","executionInfo":{"status":"ok","timestamp":1682710876102,"user_tz":240,"elapsed":5,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}}},"outputs":[],"source":["import json\n","\n","def dump_as_json(dataset, filename):\n","    \"\"\"\n","    Takes a list of dicts and dumps it as a json file that torchtext can parse.\n","    \"\"\"\n","    with open(filename, \"w\") as file:\n","        for d in dataset:\n","            file.write(json.dumps(d))\n","            file.write(\"\\n\")\n"]},{"cell_type":"code","execution_count":138,"metadata":{"id":"lprbGYNEQUqn","executionInfo":{"status":"ok","timestamp":1682710878989,"user_tz":240,"elapsed":2892,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}}},"outputs":[],"source":["KNOWLEDGE = data.Field(tokenize='spacy', tokenizer_language=\"en_core_web_sm\", include_lengths = True)\n","RESPONSE = data.Field(tokenize='spacy', tokenizer_language=\"en_core_web_sm\", include_lengths = True)\n","HISTORY = data.Field(tokenize='spacy', tokenizer_language=\"en_core_web_sm\", include_lengths = True)\n","LABEL = data.LabelField(dtype=torch.float)\n","\n","ALL = data.Field(tokenize='spacy', tokenizer_language=\"en_core_web_sm\", include_lengths = True)"]},{"cell_type":"code","execution_count":139,"metadata":{"id":"h-8aVlf5QUqn","executionInfo":{"status":"ok","timestamp":1682710883479,"user_tz":240,"elapsed":4492,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}}},"outputs":[],"source":["dump_as_json(critic_preprocess(faithdial_dataset[\"test\"]), PROJECT_ROOT + \"data/faithdial_dataset_test.json\")\n","dump_as_json(critic_preprocess(faithdial_dataset[\"train\"]), PROJECT_ROOT + \"data/faithdial_dataset_train.json\")\n","dump_as_json(critic_preprocess(faithdial_dataset[\"validation\"]), PROJECT_ROOT + \"data/faithdial_dataset_validation.json\")"]},{"cell_type":"code","execution_count":140,"metadata":{"id":"V0aO873yQUqo","executionInfo":{"status":"ok","timestamp":1682710903374,"user_tz":240,"elapsed":19898,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}}},"outputs":[],"source":["# fields = {\"knowledge\": (\"k\", KNOWLEDGE), \"response\": (\"r\", RESPONSE), \"hallucination\": (\"l\", LABEL), \"history\": (\"h\", HISTORY)}\n","fields = {\"all\": (\"a\", ALL), \"hallucination\": (\"l\", LABEL)}\n","\n","dataset = data.TabularDataset.splits(path=PROJECT_ROOT + \"data\",\n","                                     train=\"faithdial_dataset_train.json\",\n","                                     validation=\"faithdial_dataset_validation.json\",\n","                                     test=\"faithdial_dataset_test.json\",\n","                                     format=\"json\",\n","                                     fields=fields)\n"]},{"cell_type":"code","execution_count":141,"metadata":{"id":"wpa0b_BcQUqo","executionInfo":{"status":"ok","timestamp":1682710903375,"user_tz":240,"elapsed":20,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}}},"outputs":[],"source":["train_data, valid_data, test_data = dataset"]},{"cell_type":"code","execution_count":142,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CB3RjeFzQUqo","executionInfo":{"status":"ok","timestamp":1682710903375,"user_tz":240,"elapsed":19,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}},"outputId":"65bdf59e-96f7-4815-e1ee-7b512a887adf"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torchtext.data.example.Example at 0x7f48f85579d0>"]},"metadata":{},"execution_count":142}],"source":["train_data[0]"]},{"cell_type":"code","execution_count":143,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CUIjXBl-QUqp","executionInfo":{"status":"ok","timestamp":1682710903376,"user_tz":240,"elapsed":18,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}},"outputId":"dbc5ddc2-6910-486a-e179-c340fe433492"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'a': ['Can',\n","  'you',\n","  'imagine',\n","  'the',\n","  'world',\n","  'without',\n","  'internet',\n","  'access',\n","  '?',\n","  '<',\n","  'eos',\n","  '>',\n","  'Internet',\n","  'access',\n","  'was',\n","  'once',\n","  'rare',\n","  ',',\n","  'but',\n","  'has',\n","  'grown',\n","  'rapidly',\n","  '.',\n","  '<',\n","  'eos',\n","  '>',\n","  'No',\n","  'I',\n","  'could',\n","  'not',\n","  '!',\n","  'I',\n","  'could',\n","  \"n't\",\n","  'imagine',\n","  'living',\n","  'when',\n","  'internet',\n","  'access',\n","  'was',\n","  'rare',\n","  'and',\n","  'very',\n","  'few',\n","  'people',\n","  'had',\n","  'it',\n","  '!'],\n"," 'l': 'yes'}"]},"metadata":{},"execution_count":143}],"source":["vars(train_data.examples[0])"]},{"cell_type":"code","execution_count":144,"metadata":{"id":"lD7OVfyOQUqp","executionInfo":{"status":"ok","timestamp":1682710904718,"user_tz":240,"elapsed":1358,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}}},"outputs":[],"source":["KNOWLEDGE.build_vocab(train_data,\n","                      max_size=MAX_VOCAB_SIZE,\n","                      vectors = \"fasttext.simple.300d\",\n","                      unk_init = torch.Tensor.normal_)\n","RESPONSE.build_vocab(train_data,\n","                     max_size=MAX_VOCAB_SIZE,\n","                     vectors = \"fasttext.simple.300d\",\n","                     unk_init = torch.Tensor.normal_)\n","HISTORY.build_vocab(train_data,\n","                    max_size=MAX_VOCAB_SIZE,\n","                    vectors = \"fasttext.simple.300d\",\n","                    unk_init = torch.Tensor.normal_)\n","LABEL.build_vocab(train_data)\n","\n","ALL.build_vocab(train_data,\n","                specials=[\"<eos>\"],\n","                max_size=MAX_VOCAB_SIZE,\n","                vectors = \"fasttext.simple.300d\",\n","                unk_init = torch.Tensor.normal_)\n"]},{"cell_type":"code","execution_count":145,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zBEl747NQUqp","executionInfo":{"status":"ok","timestamp":1682710904718,"user_tz":240,"elapsed":9,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}},"outputId":"f02d13cb-8043-4d30-9aa0-d7ef41a8e816"},"outputs":[{"output_type":"stream","name":"stdout","text":["Unique tokens in KNOWLEDGE vocabulary: 2\n","Unique tokens in RESPONSE vocabulary: 2\n","Unique tokens in HISTORY vocabulary: 2\n","Unique tokens in LABEL vocabulary: 2\n","Unique tokens in ALL vocabulary: 25003\n"]}],"source":["print(f\"Unique tokens in KNOWLEDGE vocabulary: {len(KNOWLEDGE.vocab)}\")\n","print(f\"Unique tokens in RESPONSE vocabulary: {len(RESPONSE.vocab)}\")\n","print(f\"Unique tokens in HISTORY vocabulary: {len(HISTORY.vocab)}\")\n","print(f\"Unique tokens in LABEL vocabulary: {len(LABEL.vocab)}\")\n","\n","print(f\"Unique tokens in ALL vocabulary: {len(ALL.vocab)}\")"]},{"cell_type":"code","execution_count":146,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oYD0okYXQUqp","executionInfo":{"status":"ok","timestamp":1682710904719,"user_tz":240,"elapsed":8,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}},"outputId":"4e8c3fc6-f0ad-4891-b508-ab4c0f4805a1"},"outputs":[{"output_type":"stream","name":"stdout","text":["[]\n","[]\n","[]\n","[('no', 20474), ('yes', 13507)]\n","[(',', 204210), ('.', 194505), ('the', 136207), ('I', 132588), ('a', 94289), ('of', 85297), ('and', 79933), ('?', 77908), ('is', 72173), ('to', 68896), ('>', 67993), ('<', 67966), ('eos', 67962), ('in', 64071), ('you', 62139), ('that', 58011), ('it', 46102), ('know', 44239), (\"'s\", 32481), ('are', 32411)]\n"]}],"source":["print(KNOWLEDGE.vocab.freqs.most_common(20))\n","print(RESPONSE.vocab.freqs.most_common(20))\n","print(HISTORY.vocab.freqs.most_common(20))\n","print(LABEL.vocab.freqs.most_common(20))\n","\n","print(ALL.vocab.freqs.most_common(20))"]},{"cell_type":"code","execution_count":147,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ulp3hp87QUqq","executionInfo":{"status":"ok","timestamp":1682710904719,"user_tz":240,"elapsed":6,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}},"outputId":"b26f69c5-7144-4e4b-c255-edd41329840d"},"outputs":[{"output_type":"stream","name":"stdout","text":["['<unk>', '<pad>']\n","['<unk>', '<pad>']\n","['<unk>', '<pad>']\n","['no', 'yes']\n","['<unk>', '<pad>', '<eos>', ',', '.', 'the', 'I', 'a', 'of', 'and']\n"]}],"source":["print(KNOWLEDGE.vocab.itos[:10])\n","print(RESPONSE.vocab.itos[:10])\n","print(HISTORY.vocab.itos[:10])\n","print(LABEL.vocab.itos[:10])\n","\n","print(ALL.vocab.itos[:10])"]},{"cell_type":"code","execution_count":148,"metadata":{"id":"vTvVnXnvQUqq","executionInfo":{"status":"ok","timestamp":1682710904720,"user_tz":240,"elapsed":5,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}}},"outputs":[],"source":["BATCH_SIZE = 64\n","\n","train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n","    (train_data, valid_data, test_data),\n","    batch_size = BATCH_SIZE,\n","    sort_within_batch = True,\n","    # sort_key = lambda x: x.r,\n","    sort_key = lambda x: x.a,\n","    device = device)"]},{"cell_type":"code","execution_count":149,"metadata":{"id":"4NPgijQBQUqq","executionInfo":{"status":"ok","timestamp":1682710904720,"user_tz":240,"elapsed":5,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}}},"outputs":[],"source":["from torch import nn\n","\n","class LSTM(nn.Module):\n","    def __init__(self, response_vocab_size, knowledge_vocab_size, history_vocab_size, embedding_dim, hidden_dim, output_dim, n_layers,\n","                 bidirectional, dropout, response_pad_idx, knowledge_pad_idx, history_pad_idx):\n","\n","        super().__init__()\n","\n","        # Initialize Embedding Layer\n","        self.response_embedding = nn.Embedding(num_embeddings=response_vocab_size,\n","                                               embedding_dim=embedding_dim,\n","                                               padding_idx=response_pad_idx)\n","\n","        self.knowledge_embedding = nn.Embedding(num_embeddings=knowledge_vocab_size,\n","                                                embedding_dim=embedding_dim,\n","                                                padding_idx=knowledge_pad_idx)\n","        \n","        self.history_embedding = nn.Embedding(num_embeddings=history_vocab_size,\n","                                              embedding_dim=embedding_dim,\n","                                              padding_idx=history_pad_idx)\n","\n","        # Initialize LSTM layer\n","        self.response_lstm = nn.LSTM(input_size=embedding_dim,\n","                                     hidden_size=hidden_dim,\n","                                     num_layers=n_layers,\n","                                     bidirectional=bidirectional)\n","\n","        self.knowledge_lstm = nn.LSTM(input_size=embedding_dim,\n","                                      hidden_size=hidden_dim,\n","                                      num_layers=n_layers,\n","                                      bidirectional=bidirectional)\n","        \n","        self.history_lstm = nn.LSTM(input_size=embedding_dim,\n","                                    hidden_size=hidden_dim,\n","                                    num_layers=n_layers,\n","                                    bidirectional=bidirectional)\n","\n","        # Initialize a fully connected layer with Linear transformation\n","        self.fc = nn.Linear(in_features=3*2*hidden_dim,\n","                            out_features=output_dim)\n","\n","        # Initialize Dropout\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, response, response_lengths, knowledge, knowledge_lengths, history, history_lengths):\n","        # Apply embedding layer that matches each word to its vector and apply dropout. Dim [sent_len, batch_size, emb_dim]\n","        x_r = self.response_embedding(response)\n","        x_r = self.dropout(x_r)\n","\n","        x_k = self.knowledge_embedding(knowledge)\n","        x_k = self.dropout(x_k)\n","\n","        x_h = self.history_embedding(history)\n","        x_h = self.dropout(x_h)\n","\n","        # Run the LSTM along the sentences of length sent_len.\n","        output_r, (hidden_r, cell_r) = self.response_lstm(x_r)\n","        output_k, (hidden_k, cell_k) = self.knowledge_lstm(x_k)\n","        output_h, (hidden_h, cell_h) = self.history_lstm(x_h)\n","\n","        # Concat the final forward (hidden[-2,:,:]) and backward (hidden[-1,:,:]) hidden layers and apply dropout\n","        hidden_r = torch.cat((hidden_r[-2,:,:], hidden_r[-1,:,:]), -1)\n","        hidden_k = torch.cat((hidden_k[-2,:,:], hidden_k[-1,:,:]), -1)\n","        hidden_h = torch.cat((hidden_h[-2,:,:], hidden_h[-1,:,:]), -1)\n","        hidden = torch.cat((hidden_r, hidden_k, hidden_h), -1)\n","        hidden = self.dropout(hidden)\n","\n","        return self.fc(hidden)"]},{"cell_type":"code","source":["from torch import nn\n","\n","class ConcatLSTM(nn.Module):\n","    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers,\n","                 bidirectional, dropout, pad_idx):\n","\n","        super().__init__()\n","\n","        # Initialize Embedding Layer\n","        self.embedding = nn.Embedding(num_embeddings=vocab_size,\n","                                               embedding_dim=embedding_dim,\n","                                               padding_idx=pad_idx)\n","\n","        # Initialize LSTM layer\n","        self.lstm = nn.LSTM(input_size=embedding_dim,\n","                            hidden_size=hidden_dim,\n","                            num_layers=n_layers,\n","                            bidirectional=bidirectional)\n","\n","        # Initialize a fully connected layer with Linear transformation\n","        self.fc = nn.Linear(in_features=2*hidden_dim,\n","                            out_features=output_dim)\n","\n","        # Initialize Dropout\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, all, all_lengths):\n","        # Apply embedding layer that matches each word to its vector and apply dropout. Dim [sent_len, batch_size, emb_dim]\n","        x = self.embedding(all)\n","        x = self.dropout(x)\n","\n","        # Run the LSTM along the sentences of length sent_len.\n","        output, (hidden, cell) = self.lstm(x)\n","\n","        # Concat the final forward (hidden[-2,:,:]) and backward (hidden[-1,:,:]) hidden layers and apply dropout\n","        hidden = torch.cat((hidden[-2,:,:], hidden[-1,:,:]), -1)\n","        hidden = self.dropout(hidden)\n","\n","        return self.fc(hidden)"],"metadata":{"id":"vk9Y962URy7X","executionInfo":{"status":"ok","timestamp":1682710904720,"user_tz":240,"elapsed":4,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}}},"execution_count":150,"outputs":[]},{"cell_type":"code","execution_count":151,"metadata":{"id":"QI-pxfr1QUqq","executionInfo":{"status":"ok","timestamp":1682710905296,"user_tz":240,"elapsed":13,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}}},"outputs":[],"source":["RESPONSE_INPUT_DIM = len(RESPONSE.vocab)\n","KNOWLEDGE_INPUT_DIM = len(KNOWLEDGE.vocab)\n","HISTORY_INPUT_DIM = len(HISTORY.vocab)\n","EMBEDDING_DIM = 300\n","HIDDEN_DIM = 256\n","OUTPUT_DIM = 1\n","N_LAYERS = 2\n","BIDIRECTIONAL = True\n","DROPOUT = 0.5\n","RESPONSE_PAD_IDX = RESPONSE.vocab.stoi[RESPONSE.pad_token]\n","KNOWLEDGE_PAD_IDX = KNOWLEDGE.vocab.stoi[KNOWLEDGE.pad_token]\n","HISTORY_PAD_IDX = HISTORY.vocab.stoi[HISTORY.pad_token]\n","\n","\n","# model = LSTM(RESPONSE_INPUT_DIM,\n","#              KNOWLEDGE_INPUT_DIM,\n","#              HISTORY_INPUT_DIM,\n","#              EMBEDDING_DIM,\n","#              HIDDEN_DIM,\n","#              OUTPUT_DIM,\n","#              N_LAYERS,\n","#              BIDIRECTIONAL,\n","#              DROPOUT,\n","#              RESPONSE_PAD_IDX,\n","#              KNOWLEDGE_PAD_IDX,\n","#              HISTORY_PAD_IDX)\n","\n","\n","ALL_PAD_IDX = ALL.vocab.stoi[ALL.pad_token]\n","\n","model = ConcatLSTM(len(ALL.vocab), EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM, N_LAYERS, BIDIRECTIONAL, DROPOUT, ALL_PAD_IDX)"]},{"cell_type":"code","execution_count":152,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IyXNhzOfQUqr","executionInfo":{"status":"ok","timestamp":1682710905297,"user_tz":240,"elapsed":13,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}},"outputId":"86d6e133-b90b-45d3-c714-f2286943924a"},"outputs":[{"output_type":"stream","name":"stdout","text":["The model has 10,221,157 trainable parameters\n"]}],"source":["def count_parameters(model):\n","    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n","\n","print(f'The model has {count_parameters(model):,} trainable parameters')"]},{"cell_type":"code","execution_count":153,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M5QN73gYQUqr","executionInfo":{"status":"ok","timestamp":1682710905297,"user_tz":240,"elapsed":12,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}},"outputId":"7bc5f72f-7cf4-4175-d5cb-c70030b31c04"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([2, 300])\n","torch.Size([2, 300])\n","torch.Size([2, 300])\n"]}],"source":["print(RESPONSE.vocab.vectors.shape)\n","print(KNOWLEDGE.vocab.vectors.shape)\n","print(HISTORY.vocab.vectors.shape)"]},{"cell_type":"code","execution_count":154,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x36lpus-QUqr","executionInfo":{"status":"ok","timestamp":1682710905297,"user_tz":240,"elapsed":10,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}},"outputId":"0105c180-0947-4a85-c651-66d6ce8e23ad"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 1.2538,  0.0902,  1.9940,  ...,  0.3880, -0.0469, -0.6670],\n","        [ 0.6487, -1.5245, -0.4629,  ..., -0.0669, -0.6547,  1.0335],\n","        [-2.1418,  0.7724, -0.6359,  ...,  0.6256, -0.6219, -1.0873],\n","        ...,\n","        [ 0.2151,  0.4464,  1.8746,  ..., -0.5294,  0.3751, -0.6135],\n","        [-1.2156,  0.7609, -1.9293,  ..., -0.3884, -0.3926, -0.1387],\n","        [ 0.8763, -1.6594,  1.9265,  ..., -1.4424,  0.7236,  0.6938]])"]},"metadata":{},"execution_count":154}],"source":["# model.response_embedding.weight.data.copy_(RESPONSE.vocab.vectors)\n","# model.knowledge_embedding.weight.data.copy_(KNOWLEDGE.vocab.vectors)\n","# model.history_embedding.weight.data.copy_(HISTORY.vocab.vectors)\n","\n","model.embedding.weight.data.copy_(ALL.vocab.vectors)"]},{"cell_type":"code","execution_count":155,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wxxPbBUIQUqr","executionInfo":{"status":"ok","timestamp":1682710905298,"user_tz":240,"elapsed":9,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}},"outputId":"2fecfc88-0b02-41ce-aa06-5b275d7c097d"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n","        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n","        [-2.1418,  0.7724, -0.6359,  ...,  0.6256, -0.6219, -1.0873],\n","        ...,\n","        [ 0.2151,  0.4464,  1.8746,  ..., -0.5294,  0.3751, -0.6135],\n","        [-1.2156,  0.7609, -1.9293,  ..., -0.3884, -0.3926, -0.1387],\n","        [ 0.8763, -1.6594,  1.9265,  ..., -1.4424,  0.7236,  0.6938]])\n"]}],"source":["UNK_IDX_R = RESPONSE.vocab.stoi[RESPONSE.unk_token]\n","UNK_IDX_K = RESPONSE.vocab.stoi[KNOWLEDGE.unk_token]\n","UNK_IDX_H = RESPONSE.vocab.stoi[HISTORY.unk_token]\n","\n","UNK_IDX_A = ALL.vocab.stoi[ALL.unk_token]\n","\n","# model.response_embedding.weight.data[UNK_IDX_R] = torch.zeros(EMBEDDING_DIM)\n","# model.response_embedding.weight.data[RESPONSE_PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n","\n","# model.knowledge_embedding.weight.data[UNK_IDX_K] = torch.zeros(EMBEDDING_DIM)\n","# model.knowledge_embedding.weight.data[KNOWLEDGE_PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n","\n","# model.history_embedding.weight.data[UNK_IDX_H] = torch.zeros(EMBEDDING_DIM)\n","# model.history_embedding.weight.data[HISTORY_PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n","\n","model.embedding.weight.data[UNK_IDX_A] = torch.zeros(EMBEDDING_DIM)\n","model.embedding.weight.data[ALL_PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n","\n","# print(model.response_embedding.weight.data)\n","# print(model.knowledge_embedding.weight.data)\n","# print(model.history_embedding.weight.data)\n","\n","print(model.embedding.weight.data)"]},{"cell_type":"code","execution_count":156,"metadata":{"id":"qbo5y26lQUqr","executionInfo":{"status":"ok","timestamp":1682710905298,"user_tz":240,"elapsed":7,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}}},"outputs":[],"source":["import torch.optim as optim\n","\n","optimizer = optim.Adam(model.parameters())"]},{"cell_type":"code","execution_count":157,"metadata":{"id":"p1jpbDlCQUqs","executionInfo":{"status":"ok","timestamp":1682710905298,"user_tz":240,"elapsed":7,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}}},"outputs":[],"source":["criterion = nn.BCEWithLogitsLoss()\n","\n","model = model.to(device)\n","criterion = criterion.to(device)"]},{"cell_type":"code","execution_count":158,"metadata":{"id":"EeefTt3RQUqs","executionInfo":{"status":"ok","timestamp":1682710905299,"user_tz":240,"elapsed":8,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}}},"outputs":[],"source":["from sklearn.metrics import f1_score\n","\n","\n","def binary_accuracy(preds, y):\n","    \"\"\"\n","    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n","    \"\"\"\n","    #round predictions to the closest integer\n","    rounded_preds = torch.round(torch.sigmoid(preds))\n","    correct = (rounded_preds == y).float() #convert into float for division \n","    acc = correct.sum() / len(correct)\n","    return acc\n","\n","\n","def binary_f1(preds, y):\n","    rounded_preds = torch.round(torch.sigmoid(preds))\n","    # f1 = f1_score(y.detach().cpu(), rounded_preds.detatch().cpu(), average=\"macro\")\n","    f1 = f1_score(y.cpu(), rounded_preds.cpu(), average=\"macro\")\n","\n","    return f1\n"]},{"cell_type":"code","execution_count":159,"metadata":{"id":"syBOhKqsQUqs","executionInfo":{"status":"ok","timestamp":1682710905299,"user_tz":240,"elapsed":7,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}}},"outputs":[],"source":["def train(model, iterator, optimizer, criterion):\n","\n","    epoch_loss = 0\n","    epoch_acc = 0\n","\n","    model.train()\n","\n","    for batch in iterator:\n","\n","        optimizer.zero_grad()\n","\n","        # response, response_lengths = batch.r\n","        # knowledge, knowledge_lengths = batch.k\n","        # history, history_lengths = batch.h\n","\n","        # predictions = model(response, response_lengths, knowledge, knowledge_lengths, history, history_lengths).squeeze(1)\n","\n","\n","\n","        all, lengths = batch.a\n","        predictions = model(all, lengths).squeeze(1)\n","        \n","\n","        \n","\n","        loss = criterion(predictions, batch.l)\n","\n","        acc = binary_accuracy(predictions, batch.l)\n","\n","        loss.backward()\n","\n","        optimizer.step()\n","\n","        epoch_loss += loss.item()\n","        epoch_acc += acc.item()\n","\n","    return epoch_loss / len(iterator), epoch_acc / len(iterator)"]},{"cell_type":"code","execution_count":160,"metadata":{"id":"LU-Fvt9JQUqs","executionInfo":{"status":"ok","timestamp":1682710905299,"user_tz":240,"elapsed":7,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}}},"outputs":[],"source":["def evaluate(model, iterator, criterion):\n","\n","    epoch_loss = 0\n","    epoch_acc = 0\n","    epoch_f1 = 0\n","\n","    model.eval()\n","\n","    with torch.no_grad():\n","\n","        for batch in iterator:\n","            # response, response_lengths = batch.r\n","            # knowledge, knowledge_lengths = batch.k\n","            # history, history_lengths = batch.h\n","\n","            # predictions = model(response, response_lengths, knowledge, knowledge_lengths, history, history_lengths).squeeze(1)\n","\n","\n","            all, lengths = batch.a\n","            predictions = model(all, lengths).squeeze(1)\n","\n","\n","            loss = criterion(predictions, batch.l)\n","            acc = binary_accuracy(predictions, batch.l)\n","            f1 = binary_f1(predictions, batch.l)\n","\n","            epoch_loss += loss.item()\n","            epoch_acc += acc.item()\n","            epoch_f1 += f1.item()\n","\n","    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_f1 / len(iterator)"]},{"cell_type":"code","execution_count":161,"metadata":{"id":"lMpGhV9jQUqs","executionInfo":{"status":"ok","timestamp":1682710905299,"user_tz":240,"elapsed":6,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}}},"outputs":[],"source":["import time\n","\n","def epoch_time(start_time, end_time):\n","    elapsed_time = end_time - start_time\n","    elapsed_mins = int(elapsed_time / 60)\n","    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n","    return elapsed_mins, elapsed_secs"]},{"cell_type":"code","execution_count":162,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1asXdkH-QUqs","executionInfo":{"status":"ok","timestamp":1682711246485,"user_tz":240,"elapsed":341192,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}},"outputId":"87b8f425-2862-4e75-d1b9-0efb5e3ee27a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 01 | Epoch Time: 1m 6s\n","\tTrain Loss: 0.674 | Train Acc: 60.29% |\n","\t Val. Loss: 0.673 |  Val. Acc: 60.13% | Val. F1: 0.379\n","Epoch: 02 | Epoch Time: 1m 7s\n","\tTrain Loss: 0.675 | Train Acc: 60.09% |\n","\t Val. Loss: 0.672 |  Val. Acc: 60.14% | Val. F1: 0.378\n","Epoch: 03 | Epoch Time: 1m 8s\n","\tTrain Loss: 0.674 | Train Acc: 60.22% |\n","\t Val. Loss: 0.672 |  Val. Acc: 60.24% | Val. F1: 0.385\n","Epoch: 04 | Epoch Time: 1m 8s\n","\tTrain Loss: 0.671 | Train Acc: 60.42% |\n","\t Val. Loss: 0.672 |  Val. Acc: 60.17% | Val. F1: 0.378\n","Epoch: 05 | Epoch Time: 1m 9s\n","\tTrain Loss: 0.675 | Train Acc: 59.90% |\n","\t Val. Loss: 0.673 |  Val. Acc: 60.14% | Val. F1: 0.378\n"]}],"source":["N_EPOCHS = 5\n","path = PROJECT_ROOT + \"/\" + MODEL_CONFIG + \"_model.pt\"\n","best_valid_loss = float('inf')\n","\n","for epoch in range(N_EPOCHS):\n","\n","    start_time = time.time()\n","\n","    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n","    valid_loss, valid_acc, valid_f1 = evaluate(model, valid_iterator, criterion)\n","\n","    end_time = time.time()\n","\n","    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n","\n","    if valid_loss < best_valid_loss:\n","        best_valid_loss = valid_loss\n","        torch.save(model.state_dict(), path)\n","\n","    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n","    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}% |')\n","    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}% | Val. F1: {valid_f1:.3f}')"]},{"cell_type":"code","execution_count":163,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t5aHFK_HQUqs","executionInfo":{"status":"ok","timestamp":1682711251703,"user_tz":240,"elapsed":5233,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}},"outputId":"eb2f2a0f-fa14-441c-f25f-b5a0ff478410"},"outputs":[{"output_type":"stream","name":"stdout","text":["Test Loss: 0.670 | Test Acc: 60.59% | Test F1: 0.39\n"]}],"source":["model.load_state_dict(torch.load(path, map_location=device))\n","\n","test_loss, test_acc, test_f1 = evaluate(model, test_iterator, criterion)\n","\n","print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}% | Test F1: {test_f1:.2f}')"]},{"cell_type":"code","source":["import spacy\n","nlp = spacy.load('en_core_web_sm')\n","\n","def predict_hallucination(model, knowledge, response):\n","    model.eval()\n","\n","    tokenized_r = [tok.text for tok in nlp.tokenizer(response)]\n","    indexed_r = [RESPONSE.vocab.stoi[t] for t in tokenized_r]\n","    length_r = [len(indexed_r)]\n","    tensor_r = torch.LongTensor(indexed_r).to(device)\n","    tensor_r = tensor_r.unsqueeze(1)\n","    length_tensor_r = torch.LongTensor(length_r)\n","\n","    tokenized_k = [tok.text for tok in nlp.tokenizer(knowledge)]\n","    indexed_k = [KNOWLEDGE.vocab.stoi[t] for t in tokenized_k]\n","    length_k = [len(indexed_k)]\n","    tensor_k = torch.LongTensor(indexed_k).to(device)\n","    tensor_k = tensor_k.unsqueeze(1)\n","    length_tensor_k = torch.LongTensor(length_k)\n","\n","    prediction = torch.sigmoid(model(tensor_r, length_tensor_r, tensor_k, length_tensor_k))\n","\n","    return prediction.item()\n"],"metadata":{"id":"iOoouH7OUMHJ","executionInfo":{"status":"ok","timestamp":1682711252052,"user_tz":240,"elapsed":363,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}}},"execution_count":164,"outputs":[]},{"cell_type":"code","source":["predict_hallucination(model, \"\", \"I love dogs\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":311},"id":"uCFZFBo1U3MO","executionInfo":{"status":"error","timestamp":1682711252052,"user_tz":240,"elapsed":12,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}},"outputId":"0314ae74-4581-4039-c632-386b1e0da306"},"execution_count":165,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-165-24053f06acd2>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredict_hallucination\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"I love dogs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-164-d7b7bc3a242a>\u001b[0m in \u001b[0;36mpredict_hallucination\u001b[0;34m(model, knowledge, response)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mlength_tensor_k\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlength_k\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_r\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength_tensor_r\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength_tensor_k\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: ConcatLSTM.forward() takes 3 positional arguments but 5 were given"]}]},{"cell_type":"code","source":["predict_hallucination(model, \"\", \"Dogs are animals.\")"],"metadata":{"id":"f0LU-GstVIog","executionInfo":{"status":"aborted","timestamp":1682711252053,"user_tz":240,"elapsed":12,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["predict_hallucination(model, \"\", \"I was walking my dog last week.\")"],"metadata":{"id":"8HpFk6G2VLmU","executionInfo":{"status":"aborted","timestamp":1682711252053,"user_tz":240,"elapsed":12,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["predict_hallucination(model, \"\", \"Dogs need to be walked daily.\")"],"metadata":{"id":"_ZH_nqk6VQbP","executionInfo":{"status":"aborted","timestamp":1682711252053,"user_tz":240,"elapsed":11,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_data[2].r"],"metadata":{"id":"hxV02zIwVYkH","executionInfo":{"status":"aborted","timestamp":1682711252054,"user_tz":240,"elapsed":12,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["predict_hallucination(model, \"\", \"Dylan's Candy Bar is a candy supplier.\")"],"metadata":{"id":"nytN5bp8Vkpk","executionInfo":{"status":"aborted","timestamp":1682711252054,"user_tz":240,"elapsed":12,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["predict_hallucination(model, \"\", \"Dylan's Candy Bar is my favorite great brand of candy.\")"],"metadata":{"id":"vTT3ALVCVtm0","executionInfo":{"status":"aborted","timestamp":1682711252054,"user_tz":240,"elapsed":11,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(test_data[2].h)"],"metadata":{"id":"-YUZpBhDFrXq","executionInfo":{"status":"aborted","timestamp":1682711252054,"user_tz":240,"elapsed":11,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"K1h-8pHEF01y","executionInfo":{"status":"aborted","timestamp":1682711252055,"user_tz":240,"elapsed":12,"user":{"displayName":"Andrew Mikalsen","userId":"18187530675659738375"}}},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10"},"orig_nbformat":4,"colab":{"provenance":[]},"accelerator":"GPU","gpuClass":"standard","widgets":{"application/vnd.jupyter.widget-state+json":{"21513f7ecb124c8a9fa849942f72da4f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_75231895b8ac4e1daf8b291508b0d936","IPY_MODEL_39a6868d918a4be6b7817202184acdad","IPY_MODEL_37946cf408b74026b3bdcbceee69b2f4"],"layout":"IPY_MODEL_668abf4d18f34a1a9bddda476aa9ea7a"}},"75231895b8ac4e1daf8b291508b0d936":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6d9fa821e01548b2bbce684f5fb974cc","placeholder":"​","style":"IPY_MODEL_c6de4b2df26e45469bd5ffd7fab4bd43","value":"100%"}},"39a6868d918a4be6b7817202184acdad":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_94eccd60a653411c8f467451f0b73ff5","max":7,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a4600c9a907b4a759cef16e3ba844f4f","value":7}},"37946cf408b74026b3bdcbceee69b2f4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1a9dd98bfc2c48a6b51197c335c4d7de","placeholder":"​","style":"IPY_MODEL_3c788343e3fb4681902e9eefa6473ae2","value":" 7/7 [00:00&lt;00:00, 114.50it/s]"}},"668abf4d18f34a1a9bddda476aa9ea7a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6d9fa821e01548b2bbce684f5fb974cc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c6de4b2df26e45469bd5ffd7fab4bd43":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"94eccd60a653411c8f467451f0b73ff5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a4600c9a907b4a759cef16e3ba844f4f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1a9dd98bfc2c48a6b51197c335c4d7de":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3c788343e3fb4681902e9eefa6473ae2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}